<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Building a Rusty, Lock-free Dynamically Resizable Array</title>
        <meta name="robots" content="noindex" />


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="intro/intro.html">Introduction</a></li><li class="chapter-item expanded "><a href="intro/goal.html"><strong aria-hidden="true">1.</strong> This Book</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="intro/message.html"><strong aria-hidden="true">1.1.</strong> A Message</a></li></ol></li><li class="chapter-item expanded "><a href="concurrency/intro.html"><strong aria-hidden="true">2.</strong> Concurrency</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="concurrency/keywords.html"><strong aria-hidden="true">2.1.</strong> Keywords</a></li></ol></li><li class="chapter-item expanded "><a href="atomics/intro.html"><strong aria-hidden="true">3.</strong> Atomics</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="atomics/memory_orderings.html"><strong aria-hidden="true">3.1.</strong> What are Memory Orderings?</a></li><li class="chapter-item expanded "><a href="atomics/cas.html"><strong aria-hidden="true">3.2.</strong> Compare-and-Swap</a></li></ol></li><li class="chapter-item expanded "><a href="paper/intro.html"><strong aria-hidden="true">4.</strong> Introduction to the Paper</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="paper/structure_memory.html"><strong aria-hidden="true">4.1.</strong> Structure: Memory</a></li><li class="chapter-item expanded "><a href="paper/structure_sync.html"><strong aria-hidden="true">4.2.</strong> Structure: Synchronization</a></li><li class="chapter-item expanded "><a href="paper/algorithm.html"><strong aria-hidden="true">4.3.</strong> The Algorithm</a></li></ol></li><li class="chapter-item expanded "><a href="code/starting_code.html"><strong aria-hidden="true">5.</strong> Starting Code</a></li><li class="chapter-item expanded "><a href="code/structs.html"><strong aria-hidden="true">6.</strong> Memory Allocation</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="code/alloc/get.html"><strong aria-hidden="true">6.1.</strong> get</a></li><li class="chapter-item expanded "><a href="code/alloc/allocate_bucket.html"><strong aria-hidden="true">6.2.</strong> allocate_bucket</a></li><li class="chapter-item expanded "><a href="code/alloc/reserve.html"><strong aria-hidden="true">6.3.</strong> reserve</a></li></ol></li><li class="chapter-item expanded "><a href="code/ops/ops.html"><strong aria-hidden="true">7.</strong> Operations</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="code/ops/new.html"><strong aria-hidden="true">7.1.</strong> new</a></li><li class="chapter-item expanded "><a href="code/ops/complete_write.html"><strong aria-hidden="true">7.2.</strong> complete_write</a></li><li class="chapter-item expanded "><a href="code/ops/push.html"><strong aria-hidden="true">7.3.</strong> push</a></li><li class="chapter-item expanded "><a href="code/ops/pop.html"><strong aria-hidden="true">7.4.</strong> pop</a></li><li class="chapter-item expanded "><a href="code/ops/size.html"><strong aria-hidden="true">7.5.</strong> size</a></li><li class="chapter-item expanded "><a href="code/ops/tests.html"><strong aria-hidden="true">7.6.</strong> tests</a></li></ol></li><li class="chapter-item expanded "><a href="code/reclaim/problem.html"><strong aria-hidden="true">8.</strong> Memory Reclamation</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="code/reclaim/hazptr.html"><strong aria-hidden="true">8.1.</strong> Hazard Pointers</a></li><li class="chapter-item expanded "><a href="code/reclaim/complete_write.html"><strong aria-hidden="true">8.2.</strong> Fixing complete_write</a></li><li class="chapter-item expanded "><a href="code/reclaim/push_pop.html"><strong aria-hidden="true">8.3.</strong> Fixing push & pop</a></li><li class="chapter-item expanded "><a href="code/reclaim/vector_drop.html"><strong aria-hidden="true">8.4.</strong> Dropping the vector</a></li><li class="chapter-item expanded "><a href="code/reclaim/tests.html"><strong aria-hidden="true">8.5.</strong> Final tests!</a></li></ol></li><li class="chapter-item expanded "><a href="reflections/reflection.html"><strong aria-hidden="true">9.</strong> Reflections</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="reflections/optimize.html"><strong aria-hidden="true">9.1.</strong> A Potential Optimization</a></li><li class="chapter-item expanded "><a href="reflections/unsafe.html"><strong aria-hidden="true">9.2.</strong> unsafe code</a></li><li class="chapter-item expanded "><a href="reflections/atomic.html"><strong aria-hidden="true">9.3.</strong> Atomic Intuition</a></li><li class="chapter-item expanded "><a href="reflections/debug.html"><strong aria-hidden="true">9.4.</strong> Debugging</a></li></ol></li><li class="chapter-item expanded "><a href="closing/acknowledgements.html"><strong aria-hidden="true">10.</strong> Acknowledgements</a></li><li class="chapter-item expanded "><a href="closing/resources.html"><strong aria-hidden="true">11.</strong> Helpful Resources</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Building a Rusty, Lock-free Dynamically Resizable Array</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="building-a-rusty-lock-free-dynamically-resizable-array"><a class="header" href="#building-a-rusty-lock-free-dynamically-resizable-array">Building a Rusty, Lock-free Dynamically Resizable Array</a></h1>
<p>Dedicated to RS, whom I wouldn't compare-and-swap with anyone else.</p>
<div style="break-before: page; page-break-before: always;"></div><blockquote>
<p>You can read the code we'll write and the code for the book
<a href="https://github.com/fprasx/unlocked">here</a>. The main files for the <code>Rust</code> code
are <a href="https://github.com/fprasx/unlocked/blob/main/src/leaky.rs">leaky.rs</a> and
<a href="https://github.com/fprasx/unlocked/blob/main/src/sealed.rs">sealed.rs</a>.</p>
</blockquote>
<h1 id="the-goal"><a class="header" href="#the-goal">The Goal</a></h1>
<p>This book has a few goals.</p>
<p>Inspired by
<a href="https://rust-unofficial.github.io/too-many-lists/">Learn Rust With Entirely Too Many Linked Lists</a>,
the main goal of this book is to teach you some Rust while implementing a useful
container. We'll be implementing the lock-free vector described in the paper
<a href="https://www.stroustrup.com/lock-free-vector.pdf">Lock-free Dynamically Resizable Arrays</a>
by <strong>Dechev et al., 2006</strong></p>
<p>I hope that this book will inspire other new Rustaceans like myself to push
their capabilities. I also hope that non-Rustaceans will see the how awesome
Rust is as well. No matter whether you code or not, I hope that this book will
show you a interesting area of computer science and a beautiful language!</p>
<h2 id="topics-well-cover"><a class="header" href="#topics-well-cover">Topics We'll Cover</a></h2>
<ul>
<li>Concurrency
<ul>
<li>Cache</li>
<li>Exponential Backoff</li>
</ul>
</li>
<li>Atomics
<ul>
<li>Memory Orderings</li>
<li>Compare-and-Swap</li>
</ul>
</li>
<li>Memory Management
<ul>
<li>Allocations in Rust</li>
<li>Hazard Pointers</li>
</ul>
</li>
<li>Using Rust
<ul>
<li><code>Box</code></li>
<li><code>Drop</code></li>
</ul>
</li>
<li>Using <code>unsafe</code> Rust
<ul>
<li>Raw Pointers</li>
<li>How to write <code>unsafe</code> code</li>
</ul>
</li>
<li><strong>Anything else I find interesting!</strong></li>
</ul>
<h2 id="necessary-experience"><a class="header" href="#necessary-experience">Necessary Experience</a></h2>
<h3 id="tldr-its-good-to-know-some-rust"><a class="header" href="#tldr-its-good-to-know-some-rust">tl;dr it's good to know some Rust</a></h3>
<p>It will be helpful to be familiar with Rust or another language like C and C++,
as we will be dealing with low-level constructs like pointers, atomics, and
memory management. <strong>However</strong>, even if you are only familiar with <code>Some(_)</code> or
<code>None</code> of these things, I believe you will be able to learn an interesting thing
or two. I should say though, there is a <em>lot</em> of code in the later portions of
the book.</p>
<p>Of course, the code will be in Rust, so prior knowledge will be helpful. I'm not
going to spend time explaining syntax. However, I will comment the code well and
explain what is going on. I think if you're comfortable with the first 15
chapters of <a href="https://doc.rust-lang.org/book/">The Book</a>, you should be fine.
Even if not, as long as you understand most of Rust syntax and are fine with
looking something up every once in a while, you'll be fine.
<a href="https://doc.rust-lang.org/book/ch16-00-concurrency.html">Chapter 16</a> is very
helpful as well as it's the chapter on concurrency.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="a-message"><a class="header" href="#a-message">A Message</a></h2>
<p>Although I want you to come away from this book having learned something, and
hopefully feeling inspired to write more exciting code, this book is also a
learning experience for me.</p>
<p>I've never used Markdown before except for writing GitHub README's that only I'm
going to read, so simply using Mdbook is super exciting! I think Markdown is
cool because it's like HTML for lazy people (and I am <strong>very</strong> lazy).</p>
<p>Throughout the book, I will have many questions. I started teaching myself Rust
around ~half a year ago, so perhaps I'm not really qualified to write this book.
I'd never touched an atomic variable before I started this project (and I still
<em>technically</em> haven't), so I really mean it when I say this is a learning
experience for me. I'll try to document the answers to the questions I have so
you can learn from them as well. There will also be a whole section of
reflections, as this is also for a school project. You might enjoy that section
more than the technical sections.</p>
<p>Before we get started, I want to clarify the structure of the book. There are
three main &quot;sections&quot;: Theory/Algorithm, Code, and Reflections. Feel free to
bounce around if one section becomes too much.</p>
<p>And without further ado . . . <code>cargo run!</code></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="concurrency"><a class="header" href="#concurrency">Concurrency</a></h1>
<p><strong>Concurrent</strong> (Merriam-Webster): operating or occurring at the same time</p>
<p>Concurrent programming is simply programming that involves more than one event
happening at a time, in the sense that we think of events in a program
happening. In a non-concurrent program, if we wanted to perform two
calculations, we would perform one, and <em>then</em> the other. In a concurrent
approach, we might spawn two threads, and assign each of them a calculation to
perform. A big idea in concurrent programming is having multiple processes
running at the same time. You can think of it like your computer running Firefox
<em>and</em> Spotify at the same time.<sup class="footnote-reference"><a href="#1">1</a></sup></p>
<p>On a hardware level, one way to implement concurrency to have multiple CPU cores
(processors, the chips that do the math). Thus, we can add two numbers on one
core while dividing two numbers on another core.</p>
<p><sup class="footnote-reference"><a href="#1">1</a></sup> Your computer might actually just be switching between the applications
really fast if you only have one CPU core, giving the illusion of multiple
processes happening at the same time. Even if you have many cores, it's possible
that the the applications could be running on the same core. It's all up to the
task scheduler.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="keywords"><a class="header" href="#keywords">Keywords</a></h1>
<p><strong>Note</strong>: don't read all of this if it's boring, just come back if there is a
word you don't know later on.</p>
<h3 id="shared-state"><a class="header" href="#shared-state">Shared-state</a></h3>
<p>A concurrency model where multiple threads operate on the same memory.</p>
<h3 id="lock-free"><a class="header" href="#lock-free">Lock-free</a></h3>
<p>A property of a system where after some finite number of time steps, a thread
will make progress.</p>
<blockquote>
<p>Ok, but what does lock-free actually mean? Suppose we have a thread holding a
mutex. If that thread gets scheduled off by the OS, and never gets scheduled
on again, no other threads can get the mutex and make progress. With a
lock-free algorithm, we are guaranteed that after <em>some</em> amount of time, at
least one thread will make progress; one thread cannot block all of the others
indefinitely.</p>
</blockquote>
<h3 id="buffer"><a class="header" href="#buffer">Buffer</a></h3>
<p>Some block of memory that we use to hold data. The vector's buffers are where we
hold the actual elements.</p>
<h3 id="cache"><a class="header" href="#cache">Cache</a></h3>
<p>A type of memory that is faster to access but has less capacity that main memory
(RAM). If we need a value frequently, we can cache it so that accesses are
faster.</p>
<h3 id="null-pointer"><a class="header" href="#null-pointer">Null Pointer</a></h3>
<p>The pointer with address <code>0x0</code>. Never safe to dereference.</p>
<h3 id="heap"><a class="header" href="#heap">Heap</a></h3>
<p>A region of memory for storing long-lived or large values.</p>
<h3 id="stack"><a class="header" href="#stack">Stack</a></h3>
<p>A region of memory for storing local variables and small variables.</p>
<h3 id="data-race"><a class="header" href="#data-race">Data race</a></h3>
<p>When multiple threads access a value without synchronization and one of them is
writing. Picture a shared Google document. If people are trying to read it as
someone writes on it, they'll be reading gibberish until the writer is done.</p>
<h3 id="thread"><a class="header" href="#thread">Thread</a></h3>
<p>Like another program running within the main program. Threads can run the same
time as each other, and the first thread (the one we have at program start) is
called the <em>main thread</em>. Eventually, all threads are <em>joined</em> back into the
main thread.</p>
<h3 id="mutex-mutual-exclusion"><a class="header" href="#mutex-mutual-exclusion">Mutex {mut}ual {ex}clusion</a></h3>
<p>A data structure that gives a thread exclusive access to some data. When you
call <code>lock</code> on a <code>Mutex</code>, you block until the <code>Mutex</code> is unlocked and you get
the lock. Then, you can do whatever you want with the data inside. Once you're
done, you unlock the <code>Mutex</code> to relinquish it back to the other threads.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="atomics"><a class="header" href="#atomics">Atomics</a></h1>
<p>Besides having a cool name, atomics are crucial for writing concurrent code.</p>
<p>We first need to think about how computers perform operations. On a a 32-bit
machine, loading (reading) a 64-bit value would require two CPU operations, one
for the first 32 bits and one for the second 32 bits.</p>
<p>Suppose each box represents a byte (8 bits):</p>
<pre><code>
v    Load 1             v
+-----+-----+-----+-----+-----+-----+-----+-----+
|     |     |     |     |     |     |     |     |
+-----+-----+-----+-----+-----+-----+-----+-----+
                        ^         Load 2        ^
</code></pre>
<p>This shows how a load of a variable can take multiple steps.</p>
<p><strong>Atomic</strong> operations take only one step. They have no intermediate observable
state, which means the CPU only observes them as having happened or not.</p>
<p>This is very important in multithreaded scenarios because if threads use
non-atomic operations, loads and scores might end up overlapping, resulting in
<em>torn</em> reads and writes.</p>
<p>For example, on our hypothetical 32-bit machine, one core might finish the first
write to the 32-bit value, another core then might perform the two loads needed
to load the value, and then the first core might finish the storing the last 32
bits. Now, one core has a value that is half gibberish!</p>
<p>This is an example of a data race, an example of undefined behavior.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="what-are-memory-orderings"><a class="header" href="#what-are-memory-orderings">What are Memory Orderings?</a></h1>
<p>In a concurrent environment, each variable has a modification history, all the
values it has been. Say we have a variable A. We could store 1 into it, then 2,
then 3.</p>
<p>The problem comes from the fact that another thread reading A can &quot;read&quot; any of
those values, <strong>even after the last store is executed, &quot;in real time&quot;.</strong> For
example, it might have an older (stale) copy of the variable cached.</p>
<p>To ensure that our programs run the way we want, we need to specify more
explicitly which values in the modification history the CPU is allowed to use.</p>
<p>Another problem is the compiler reordering instructions. The Golden Rule of
instruction reordering is <strong>do not modify the behavior of a single-threaded
program</strong>. The compiler might not think it's doing anything wrong moving some
instructions around in one thread. And from the perspective of the thread that's
being modified, everything will seem alright. Other threads might start
receiving crazy results though.</p>
<p>An <em>ordering</em> is a parameter you provide to operations with atomic variables
that specifies which reorderings can happen and which values in the modification
history the CPU can use.</p>
<p>I'm not going to go super in-depth into the intricacies of each ordering, but I
will explain the important parts of each. If you're curious, Jon Gjenset has a
great youtube video on Atomics, which sections on each ordering:
<a href="https://www.youtube.com/watch?v=rMGWeSjctlY">Crust of Rust: Atomics and Memory Ordering</a>.</p>
<blockquote>
<p>Going into the orderings, I find it helpful to separate their effects into two
categories: those that have to do with compiler reordering, and those that
have to do with the CPU. The compiler deals with the synchronization in the
operation's thread, (well, actually the CPU does too, but that's a different
story), and the CPU handles the synchronization across the other threads.</p>
</blockquote>
<h2 id="relaxed"><a class="header" href="#relaxed">Relaxed</a></h2>
<p>The first ordering is <code>Relaxed</code>. When it comes to the CPU, there are no
guarantees imposed by this ordering. The compiler can reorder <code>Relaxed</code>
operations as long it follows the Golden Rule; it does not need to consider
other threads. The classic use case (I think this use case is classic at least,
I always see it used in examples) of the <code>Relaxed</code> ordering is
incrementing/decrementing a counter. We don't really care about observing the
state of the counter; we just want to make sure our updates happen correctly.
When we finally load the counter, we can use an ordering with stronger
guarantees.</p>
<h2 id="release"><a class="header" href="#release">Release</a></h2>
<p><code>Release</code> is used with stores. You can think of <code>Release</code> as <code>Release</code>ing a
lock. We want any changes that happened while we had the lock to become visible
to other threads. When you store with <code>Release</code>, it's like saying &quot;I'm done with
this, use these changes.&quot; Thus, the compiler cannot reorder operations <em>after</em> a
<code>Release</code> store.</p>
<pre><code>STORE (Relaxed) ─┐
STORE (Release) -+-// &quot;Release the lock&quot;
    X          &lt;─┘ // nope, this happened while we &quot;held the lock&quot;
</code></pre>
<p>There is also a CPU property to this ordering, which I'll go over with
<code>Acquire</code>.</p>
<h2 id="acquire"><a class="header" href="#acquire">Acquire</a></h2>
<p><code>Acquire</code> is used with loads. You can think of <code>Acquire</code> like <code>Acquire</code>ing a
lock. This means that no memory operations in the current thread can get
reordered <em>before</em> taking the lock. Anything that happens after &quot;taking the
lock&quot; stays after the &quot;lock was taken&quot;.</p>
<pre><code>    X                              &lt;─┐ // nope, this happened &quot;after taking the lock&quot;
    X               &lt;─┐              │ // nope, this happened &quot;after taking the lock&quot;
LOAD (Acquire) -------+--------------+-// &quot;Take the lock&quot;
STORE (Relaxed)      ─┘              │
LOAD a different variable (Relaxed) ─┘
</code></pre>
<p><code>Acquire</code> also has an important interaction with <code>Release</code> at the CPU level. Any
load <code>Acquire</code> or stronger must see the changes published by the release store
of the same variable.</p>
<blockquote>
<p>How does this achieve proper synchronization? You see, when two <code>Ordering</code>s
love each other very much . . . we get <code>Acquire-Release</code> semantics. Watch what
happens when we use <code>Acquire</code> and <code>Release</code> together (diagram inspired by
<a href="https://preshing.com/20120913/acquire-and-release-semantics/">this blog post</a>):</p>
<!-- prettier-ignore-start -->
<pre><code>└───┘ Release store

  | Read most recent data because the load is Acquire and the store is Release
  V

┌───┐ Acquire load
Memory operations cannot go above


Memory operations cannot go below
└───┘ Release store

  | Read most recent data because the load is Acquire and the store is Release
  V

┌───┐ Acquire load
</code></pre>
<!-- prettier-ignore-end -->
<p>All operations are trapped in their own sections, and each section gets the
most recent modifications because of the way <code>Acquire</code> loads <em>synchronize</em>
with the <code>Release</code> stores.</p>
</blockquote>
<p>Note: Although the lock metaphor is helpful for understanding <code>Acquire</code> and
<code>Release</code>, remember there are no actual locks involved.</p>
<h2 id="acqrel-acquire-and-release"><a class="header" href="#acqrel-acquire-and-release">AcqRel (Acquire <em>and</em> Release)</a></h2>
<p>An <code>AcqRel</code> load/store is just <code>Release</code> for stores and <code>Acquire</code> for loads.
When used with an operation that loads <em>and</em> stores, it is both <code>Acquire</code> and
<code>Release</code>. <code>AcqRel</code>'s main use case is Read-Modify-Write operations, like
loading a variable, adding one, and storing it back. We want the load to be
<code>Acquire</code> and the store <code>Release</code> so we would use <code>AcqRel</code> to achieve this.
Foreshadowing: this ordering will play a prominent part later on!</p>
<h2 id="seqcst-sequentially-consistent"><a class="header" href="#seqcst-sequentially-consistent">SeqCst (Sequentially Consistent)</a></h2>
<p>The <code>SeqCst</code> ordering makes has the same reordering effects of <code>AcqRel</code>, and
also establishes a consistent modification order across all threads. Two stores
tagged <code>Relaxed</code> might show up in different orders to different threads.
However, if they are both tagged <code>SeqCst</code>, they will show up in the same order
to all threads. <code>SeqCst</code> is the strongest ordering, and thus also the safest
(see Jon Gjenset's video for weird things that can happen with weaker
orderings). Safety comes at a price though, with the CPU often having to
emit <em>memory fences</em><sup class="footnote-reference"><a href="#1">1</a></sup> to guarantee sequential consistency. This can affect
performance.</p>
<p><sup class="footnote-reference"><a href="#1">1</a></sup> A memory fence prevents the CPU from reordering operations in certain ways.
This is a great
<a href="https://preshing.com/20120710/memory-barriers-are-like-source-control-operations/">article</a>
which describes many different types of fences, kind of like the different
Atomic orderings, which restrict the compiler instead of the CPU.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="compare-and-swap"><a class="header" href="#compare-and-swap">Compare-and-Swap</a></h1>
<p><em>(also known as CAS and</em> <code>compare_exchange</code><em>)</em></p>
<p>Definition: swap a value with a new value <em>only if the the current value is what
we think it is.</em></p>
<p>This reason this is important is that loosely, we can say the state during the
swap is the same as the state we observed when preparing for the swap.</p>
<p>Here's a code example:</p>
<pre><code>LOAD A
CAS old = A, new = 2 * A // Only swap in the double if the number hasn't changed
</code></pre>
<p>A more realistic example with a linked list would be this;</p>
<pre><code>LOAD LIST_NODE

CAS old = LIST_NODE.pointer, new = new_pointer
</code></pre>
<p>In this case, we switch the <code>LIST_NODE</code> pointer only if it hasn't changed.</p>
<p>Here's what we did:</p>
<ol>
<li>We loaded the node</li>
<li>We read the pointer</li>
<li>We called CAS with the new pointer</li>
</ol>
<p>At this point, there are two things that can happen:</p>
<ol>
<li>The pointer changed, and the CAS fails. This means that someone else changed
the pointer first, and it's good that the CAS failed, because it's possible
the the change that succeeded invalidates the change we just tried to make.</li>
<li>The pointer is the same, and CAS succeeds. Because the pointer was the same,
our assumptions about the state of the vector held, and our change was valid.</li>
</ol>
<p>At first, this might seem contrived and confusing (as it did to me). I would
focus on this intuition: <em>if CAS succeeds, loosely, we can say the state during
the swap was the same as the state we observed when preparing for the swap.</em> Our
assumptions were consistent throughout the whole process.</p>
<p>The <code>compare_exchange</code> function in the Rust Standard Library returns a
<code>Result&lt;T, T&gt;</code>, where <code>T</code> is the type being exchanged. The <code>Result</code> contains the
value that the variable actually was. If <code>compare_exchange</code> fails, it returns
<code>Err(actual_value)</code>, on success, it returns <code>Ok(expected_value)</code> (if it
succeeded, that means <code>actual_value == expected_value</code>).</p>
<p><strong>Note</strong>: for the rest of the book, I'm going to refer to <code>compare-and-swap</code> as
<code>compare_exchange</code>, as that is what the Rust Standard Library uses. I used
<code>compare-and-swap</code> on this page because the name is very explicit about what the
operation does.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="introduction-to-the-paper"><a class="header" href="#introduction-to-the-paper">Introduction to the Paper</a></h1>
<p>Firstly, a link to the paper can be found <a href="https://www.stroustrup.com/lock-free-vector.pdf">here</a>.</p>
<p>In their 2006 paper, Dechev et al. describe an implementation for a vector than can safely be shared across threads.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="structure-of-the-vector"><a class="header" href="#structure-of-the-vector">Structure of the vector</a></h1>
<p>This is where we begin working on the vector.</p>
<p>When thinking about the structure of the vector, I find it helpful to think
about it in two parts: memory and synchronization. By memory I mean allocation
of space and by synchronization I mean synchronizing reads and writes. Let's
start with memory.</p>
<h2 id="memory"><a class="header" href="#memory">Memory</a></h2>
<p>The vector is, broadly, a two-level array.</p>
<pre><code>+---+---+---+---+---+
| 1 | 2 | 3 | 4 | 5 | Top-level
+---+---+---+---+---+
  |   |   |   |   |
  v   v   v   v   v
+---+---+---+---+---+
| 1 | 2 | 3 | 4 | 5 | Lower-level, notice: these arrays are represented vertically
+---+---+---+---+---+
    | 2 | 3 | 4 | 5 |
    +---+---+---+---+
        | 3 | 4 | 5 |
        +---+---+---+
            | 4 | 5 |
            +---+---+
                | 5 |
                +---+

</code></pre>
<p>The vector stores a pointer to a first array (the top-level one). The elements
in this array are also pointers, to more arrays (the lower-level ones). This is
why this organization is called a two-level array.</p>
<p>The reason for this is resizing. Suppose we have 4 elements of capacity, and
they are all filled. We need to allocate more memory. We allocate more memory
using something like <code>malloc()</code>, and the allocator returns a pointer to the new
allocation.</p>
<p>For a normal vector, we would simply copy our vector's elements over to the new
allocation. We can't do this for a lockless vector though because copying isn't
atomic, and we can't lock down the vector, copy, and unlock. Therefore, we need
a different system.</p>
<blockquote>
<p><strong>A little tangent on allocations</strong>: When allocating memory for a normal
vector, we generally make larger and larger allocations. For example, the
first allocation could be 4 elements, the next 8, then 16, 32 . . . This
reduces the total number of allocations we need to perform, which is good for
performance. We're going to use this same idea for the vector.</p>
</blockquote>
<p>Returning to the idea of a two-level array, the first level is going to hold
pointers to blocks of memory we can call <em>buckets</em>. The amount of memory a
bucket holds is related to it's index. The first bucket will hold
<code>some constant (which we'll call FIRST_BUCKET_SIZE) times 2 to the power of its index</code>
elements. Here are some sample calculations for the first few buckets to show
the principle, using <code>FIRST_BUCKET_SIZE=8</code>:</p>
<pre><code class="language-python"># Bucket 1
CAP = FIRST_BUCKET_SIZE * 2 ^ INDEX
    = 8 * 2 ^ 0
    = 8

# Bucket 2
CAP = FIRST_BUCKET_SIZE * 2 ^ INDEX
    = 8 * 2 ^ 1
    = 16

3: 32
4: 64
To infinity and beyond . . .
</code></pre>
<p>The next part of the vector's structure is the synchronization aspect, which
goes hand in hand with explaining the algorithm. I'll cover them together.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="synchronization"><a class="header" href="#synchronization">Synchronization</a></h1>
<p>Synchronization, that is, coordinating concurrent operations on the vector, is
achieved through two little data structures: the <code>Descriptor</code> and the
<code>WriteDescriptor</code>. As you might expect, the <code>Descriptor</code> describes the vector
and the <code>WriteDescriptor</code> describes a write operation.</p>
<h3 id="the-descriptor"><a class="header" href="#the-descriptor">The Descriptor</a></h3>
<p>The descriptor holds two values: a pointer to a <code>WriteDescriptor</code>, and a value
indicating the size of the vector.</p>
<h3 id="the-writedescriptor"><a class="header" href="#the-writedescriptor">The WriteDescriptor</a></h3>
<p>The WriteDescriptor holds three values: the location of the write (a
pointer-like object), an old value, and a new value. If your spidey-sense is
tingling, it might be because this new/old business is hinting at a
<code>compare_exchange</code> in the future.</p>
<p>Now that we've seen the <code>Descriptor</code> and <code>WriteDescriptor</code>, here's a quick
summary of the vector's structure:</p>
<!-- prettier-ignore-start -->
<pre><code class="language-yaml"># Data Organization
Vector: 
    [Pointer -&gt; Memory],
    Pointer -&gt; Descriptor

Descriptor: 
    Pointer -&gt; Possible WriteDescriptor, 
    Size

WriteDescriptor: 
    Pointer -&gt; Element location, 
    New Element, 
    Old Element
</code></pre>
<!-- prettier-ignore-end -->
<h2 id="how-does-this-actually-help-with-synchronization"><a class="header" href="#how-does-this-actually-help-with-synchronization">How does this actually help with synchronization?</a></h2>
<blockquote>
<p>The major challenges of providing lock-free vector implementation stem from
the fact that key operations need to atomically modify two or more
non-colocated words (Dechev et. al., 2006)</p>
</blockquote>
<p>This translates to, &quot;We need to change two things (without locking the vector
down) to ensure the vector is in the right state.&quot; For a <code>push</code> operation, say,
we would need to change the <em>length</em> of the vector and write the new <em>data</em>.</p>
<p>The descriptor system gets around this by saying, &quot;If you want to change the
<code>Descriptor</code>, you need to complete a pending write if there is one.&quot; Why does
this ensure the correct semantics? Consider this example from the paper:</p>
<blockquote>
<p>The semantics of the <code>pop_back</code>[<code>pop</code>] and <code>push_back</code>[<code>push</code>] operations are guaranteed by
the <code>Descriptor</code> object. Consider the case when a <code>pop_back</code> is interrupted by
any matching number of <code>push_back</code> and <code>pop_back</code> operations. In a naive
implementation, the size of the vector would appear unchanged when the
original <code>pop_back</code> resumes and the operation could produce an erroneous
result. (Dechev et. al., 2006)</p>
</blockquote>
<p>Under the &quot;naive implementation&quot;, in this scenario, the vector might look like
<code>[1, 2, 3]</code>. Someone calls <code>pop</code>, and the vector should return <code>3</code>. However, the
thread gets <em>preempted</em> (the OS says another thread can run, and the current
thread is paused), and the running thread executes a bunch of <code>pop</code>s and
<code>push</code>es. The vector becomes <code>[4, 5, 6]</code>. When the original pop finally runs, it
incorrectly returns <code>6</code>.</p>
<p>Let's consider when the first <code>push</code> happens after the original <code>pop</code> under the
correct implementation. When the <code>push</code> happens, it swaps in a new <code>Descriptor</code>,
which says that the size is now one bigger and points to a new <code>WriteDescriptor</code>
representing a <code>push</code> operation. Because it swapped in a <code>Descriptor</code>, it has to
complete the operation specified in the current <code>WriteDescriptor</code>, and the
original <code>pop</code> returns <code>3</code>, as it should.</p>
<p>Let me clarify all this swapping business!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-algorithm"><a class="header" href="#the-algorithm">The Algorithm</a></h1>
<p>As I’ve said before, I think of the vector as two connected systems: memory and
synchronization. By “The Algorithm”, I mean the synchronization aspect. To
recap, synchronization is controlled by two little data structures, the
<code>Descriptor</code> and the <code>WriteDescriptor</code>. These data structures describe the
vector itself and a write operation, respectively.</p>
<p>I think the best way to explain the algorithm is to dive right in.</p>
<h2 id="complete_write"><a class="header" href="#complete_write"><code>complete_write()</code></a></h2>
<p>First, I want to explain a little routine called <code>complete_write</code>. This function
is true to its name and <em>completes</em> a <em>write</em>.</p>
<blockquote>
<p>Write means &quot;write operation&quot;, in this context, a <code>push</code> or <code>pop</code>. In my
experience, &quot;write&quot; has been a more colloquial term used in CS for whenever we
make a modification to something. Really anything can technically be a
&quot;write&quot;, but I would say things that are more final are &quot;writes&quot;. For example,
incrementing a loop variable is pretty insignificant in the grand scheme of
things, so it's not really a &quot;write&quot;, but increasing the size of the vector is
an important &quot;write&quot;. This usage might also be particular to concurrent
programming, where balancing reads/writes is an important consideration for
designing a data structure. Concurrent data structures are often designed for
infrequent writes and frequent reads. Modifications to databases (which are
<strong>heavily</strong> concurrent) can also be called writes. tl;dr a &quot;write&quot; in this
case means the details describing a particular instance of &quot;writing&quot;</p>
</blockquote>
<p><code>complete_write</code> takes two arguments, a <code>WriteDescriptor</code>, and the vector
itself. <code>complete_write</code> applies the write operation described in the
<code>WriteDescriptor</code> on the vector. Recall that a <code>WriteDescriptor</code> contains three
things: a reference/pointer to the location where the write will take place, a
new value to write, and an old value that we loaded in from the location.</p>
<p>First we perform a <code>compare_exchange</code> using the data in the <code>WriteDescriptor</code>.
We only swap in the new data if the data at the location of the swap matches the
old data we have. If the <code>compare_exchange</code> succeeds, this means that we swapped
in the value we want to write. If it fails, it means someone else beat us to it
and performed the write. Remember, many threads can access the vector's
<code>Descriptor</code> and <code>WriteDescriptor</code> at once, so many threads will be trying to
complete the same write. Only one of them can succeed. It's a fight to the
death! Arrghhh!!!</p>
<p>I'm kidding. After performing the <code>compare_exchange</code>, successful for not, we
modify the vector to indicate that there is no pending write operation. If all
threads do this, at least once will succeed, and all will indicate that there is
no pending write operations. Though some of the threads may be sad because their
<code>compare_exchange</code> failed, the vector is happy because it's in a consistent and
correct state.</p>
<h2 id="push"><a class="header" href="#push"><code>push()</code></a></h2>
<p>Now that we know writes are actually performed, let’s get into how a <code>push</code>
operation works. Here are the steps:</p>
<ol>
<li>
<p>Load in the current <code>Descriptor</code>.</p>
</li>
<li>
<p>If the <code>Descriptor</code> contains a write operation, complete it . This is important
because it ensures that before any new write operation happens, the previous
one is completed. We cannot do anything before completing the previous write
operation, so all operations <em>will</em> eventually get executed.</p>
</li>
<li>
<p>Calculate which bucket our new element will go into.</p>
</li>
<li>
<p>If that bucket has not been allocated memory yet, do so.</p>
</li>
<li>
<p>Make a new <code>WriteDescriptor</code>. The <code>new</code> value in the <code>WriteDescriptor</code> will
be the data passed into the <code>push</code> function.</p>
</li>
<li>
<p>Make a new <code>Descriptor</code> which contains the following data: the size held in
the current <code>Descriptor</code> + 1, and the new <code>WriteDescriptor</code>.</p>
</li>
<li>
<p>Now, here comes the part that makes this a <code>compare-and-swap</code> or
<code>compare_exchange</code> algorithm. We <code>compare_exchange</code> the new <code>Descriptor</code>
we made with the old one. If the <code>Descriptor</code> held in the vector didn't
change, our new <code>Descriptor</code> will replace it. If it did change, we will fail
to swap in our new <code>Descriptor</code>, and we go back to Step 1.</p>
<blockquote>
<p>Note: I think it's important to consider why this routine (particularly
step 6) ensures correctness. If the <code>compare_exchange</code> succeeds, this
means that the vector did not change in the time it took us to prepare a
new <code>Descriptor</code>. Why is this important? It means our assumptions about
the vector's state <strong>did not change</strong>. In our new <code>Descriptor</code>, we used
the size from the <code>Descriptor</code> we loaded in, and incremented that.
So, if the size we loaded in was <code>4</code>, our new <code>Descriptor</code> would say the
size of the vector is <code>5</code>. Now, imagine that we could just swap in our
fresh <code>Descriptor</code> without comparing it with the current one. If someone
else was also trying to <code>push</code>, their <code>Descriptor</code> might get swapped in
before ours. It would say the size of the vector is <code>5</code>, because it made
the same assumptions we did. Then we swap in our <code>Descriptor</code>, our
<code>Descriptor</code> would maintain that the size of the vector is <code>5</code>, even
though it should be <code>6</code> because there were two <code>push</code> operations.
Furthermore, we would overwrite the element that was <code>push</code>ed on by the
first call to <code>push</code>, because both our <code>WriteDescriptor</code>s would be
referencing the same location in memory. This is terrible!
<code>compare_exchange</code> is our friend.</p>
</blockquote>
</li>
<li>
<p>Now that we have swapped in our <code>Descriptor</code>, we execute the
<code>WriteDescriptor</code> we made using <code>complete_write</code>, finalizing the changes we
want to make to the vector.</p>
</li>
</ol>
<p>And that's a <code>push</code>!</p>
<p><code>Pop</code> pretty much works the same except for some small variations, so we'll get
into that when we implement <code>push</code>/<code>pop</code>. However, the way we make sure changes
are valid using <code>compare_exchange</code> is identical for both operations.</p>
<p>I think it's finally time to start looking at some code. When I was writing
code, it felt very different from reasoning about the theory. I really felt like
I had to consider every line I wrote and every decision I made. I'll walk you
through what I came up with now.</p>
<blockquote>
<p>Note: we're going to first write a version of the vector that doesn't reclaim
the memory it uses; it <em>leaks</em>.</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h1 id="starting-code"><a class="header" href="#starting-code">Starting Code</a></h1>
<h2 id="pseudocode"><a class="header" href="#pseudocode">Pseudocode</a></h2>
<p>This &quot;pythonesque&quot; pseudocode with some pointer operations thrown in shows the
general API and implementation details of the vector. The pseudocode is a
conversion of the paper's pseudocode into a more (in my opinion) understandable
form. It completely ignores memory reclamation.</p>
<p>You don't need to read this entire thing, it's just here as a reference.</p>
<pre><code class="language-python"># Calculate the index of the correct bucket
# Return a pointer
def at(vector, i):
    pos = i + FIRST_BUCKET_SIZE
    hibit = highest_bit(pos)
    index = pos ^ 2 ** hibit
    return &amp;vector.memory[hibit - highest_bit(FIRST_BUCKET_SIZE)][index]
</code></pre>
<pre><code class="language-python"># Perform an atomic load at the correct index
def read(vector, i):
    return *at(vector, i).load(Ordering)
</code></pre>
<pre><code class="language-python"># Perform an atomic store at the correct index
def write(vector, i, elem):
    return *at(vector, i).store(elem, Ordering)
</code></pre>
<pre><code class="language-python"># Calculate the number of allocations needed
# Then perform each allocation
def reserve(vector, size):
    i = highest_bit(vector.descriptor.size + FIRST_BUCKET_SIZE - 1)
        - highest_bit(FIRST_BUCKET_SIZE)
    if i &lt; 0 {
        i = 0
    }
    while i &lt; highest_bit(size + FIRST_BUCKET_SIZE - 1)
        - highest_bit(FIRST_BUCKET_SIZE):
        i += 1
        allocate_bucket(vector, i)
</code></pre>
<pre><code class="language-python"># Calculate the amount of memory needed
# Allocate that much memory
# Try to CAS it in
# If CAS fails, the bucket is already initalized, so free the memory
def allocate_bucket(vector, bucket):
    bucket_size = FIRST_BUCKET_SIZE * (2 ** bucket)
    mem = allocate(bucket_size)
    if not CAS(&amp;vector.memory[bucket], nullptr, mem):
        free(mem)
</code></pre>
<pre><code class="language-python"># Get the size of the current descriptor
# If there is a pending write operation, subtract one from the size
def size(vector):
    size = vector.descriptor.size
    if descriptor.writeop.pending:
        size -= 1
    return size
</code></pre>
<pre><code class="language-python"># Get the current descriptor
# Complete a pending write operation
# Allocate memory if needed
# Make a new WriteDescriptor
# Try to CAS it in
# If CAS failed go back to first step
# Complete a pending write operation
def push(vector, elem):
    while True:
        current_desc = vector.descriptor
        complete_write(vector, current_desc.pending)
        bucket = highest_bit(current_desc.size + FIRST_BUCKET_SIZE)
            - highest_bit(FIRST_BUCKET_SIZE)
        if vector.memory[bucket] == nullptr:
            allocate_bucket(vector, bucket)
        writeop = WriteDescriptor(
            *at(vector, current_desc.size),
            elem,
            current_desc.size
        )
        next_desc = Descriptor(1 + current_desc.size, writeop)
        if CAS(&amp;vector.descriptor, current_desc, next_desc):
            break
    complete_write(vector, next_desc.pending)
</code></pre>
<pre><code class="language-python"># Get the current descriptor
# Complete a pending write operation
# Read the last element of the vector
# Make a new WriteDescriptor
# Try to CAS it in
# If CAS failed go back to first step
# Return the last element
def pop(vector):
    while True:
        current_desc = vector.descriptor
        complete_write(vector, current_desc.pending)
        elem = *at(current_desc.size - 1).load(Ordering)
        next_desc = Descriptor(curr_desc.size - 1, null)
        if CAS(&amp;vector.descriptor, current_desc, next_desc):
            break
    return elem
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="memory-allocation"><a class="header" href="#memory-allocation">Memory Allocation</a></h1>
<p>The first thing I did when writing the code out was think about the pieces that
would make up the vector. In Rust, an extremely common building block for any
type is the <code>struct</code>. A <code>struct</code> just sticks its members' data next to each
other in memory. Here is the vector itself, as a struct:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct SecVec&lt;'a, T: Sized + Copy&gt; {
    buffers: CachePadded&lt;Box&lt;[AtomicPtr&lt;AtomicU64&gt;; 60]&gt;&gt;,
    descriptor: CachePadded&lt;AtomicPtr&lt;Descriptor&lt;'a, T&gt;&gt;&gt;,
    _boo: PhantomData&lt;T&gt;, // Data is stored as transmuted T's
}
<span class="boring">}</span></code></pre></pre>
<h2 id="boo-"><a class="header" href="#boo-">Boo! 👻</a></h2>
<p>I bet the <code>PhantomData</code> scared you. We have a generic parameter <code>T</code>, but we have
no <code>struct</code> members of <code>SecVec</code> or either of the descriptors that actually
contains a <code>T</code> (because we transmute <code>T</code> into <code>u64</code>s). Therefore, to let the
compiler know we really are carrying <code>T</code>'s, we add a little ghost that tells it,
&quot;We're carrying this Phantom <code>T</code> <em>wink</em> &quot;</p>
<h2 id="sharing-is-caring"><a class="header" href="#sharing-is-caring">Sharing is caring</a></h2>
<p>There is a lot to unpack here. Firstly, <code>CachePadded</code> is a <code>struct</code> provided by
the <code>crossbeam_utils</code> crate.</p>
<blockquote>
<p><strong>A note on cache</strong>: you may have heard of CPU cache, a small buffer of memory
stored on the CPU to allow for fast access. The <code>cache</code> in <code>CachePadded</code>
actually refers to a buffer between main RAM and the CPU's. It's just a larger
and slower cache compared to a CPU cache. The cache is split into contiguous
blocks of memory called <em>cache lines</em>. This is the most granular level at
which cache coherency is maintained. When multiple threads both have a value
in the same cache line, one thread modifying the value it owns marks the
<em>entire</em> cache line as &quot;dirty&quot;. Even though the other thread's value hasn't
been changed, the cache coherency protocol might cause the thread to reload
the entire line when it uses the value, incurring some overhead. This is
called <em>false sharing</em>, and cause severe performance degradation. Cache is an
extremely important consideration when data structures. It's why linked lists
are algorithmically fine but terribly slow in practice. As the saying goes,
cache is king.</p>
</blockquote>
<p>The <code>CachePadded</code> <code>struct</code> aligns its contents to the beginning of the cache
line to prevent false sharing. If all <code>CachePadded</code> objects are at the beginning
of a cache line (assuming they do not cross a cache line), there can't be false
sharing between them. Preventing false sharing can lead to a huge speedup, but
it also does increase the size of the type. If you're wondering how
<code>CachePadded</code> is implemented, check out
<a href="https://doc.rust-lang.org/nomicon/other-reprs.html"><code>#[repr(align(n))]</code></a> in the
Nomicon.</p>
<p>Here's how I picture cache padding:</p>
<pre><code>|-----Cache line-----|-----Cache Line-----|
v                    v                    v
+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
|69|xx|xx|xx|xx|xx|xx|42|xx|xx|xx|xx|xx|xx|
+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
^                    ^
 \                    \
  \                    \
   \                    \
    Different cache lines -&gt; no false sharing
</code></pre>
<h2 id="two-level-array"><a class="header" href="#two-level-array">Two-level array</a></h2>
<p>The first member of <code>SecVec&lt;T&gt;</code> is a cache-padded array of 60 pointers allocated
on the heap (notice the <code>Box</code>). These pointers will each point into another
array. The pointers start off as null pointers (<code>0x0</code>), and will get swapped out
for valid pointers once they need to point to an actual array.</p>
<p>The <code>AtomicPtr</code>s point to <code>AtomicU64</code>s because each element is going to get
transmuted into a <code>u64</code> so that we can atomically perform writes on the vector.
When returning an element, we'll transmute it back into a T. <em>Transmuting</em> means
interpreting the bits of one type as the bits of another.</p>
<p>For example, <code>0b10100001</code> means <code>-95</code> when interpreted as a signed integer but
<code>161</code> when interpreted as an unsigned integer. Transmuting one to the other
would just change how we interpret the bits, not tha actual bits themselves.</p>
<h2 id="descriptors-galore"><a class="header" href="#descriptors-galore">Descriptors galore</a></h2>
<p>The second member of <code>SecVec&lt;T&gt;</code> is a cache-padded <code>AtomicPtr</code> to a
<code>Descriptor</code>. As you've probably noticed, there are a bunch of <code>AtomicPtr</code>s
here. That's because we can modify the pointer atomically, specify which
<code>Ordering</code> to use, and <code>compare_exchange</code> the pointer. A common way of writing
data in concurrent programming is to change a pointer instead of actually
modifying a buffer. Since a buffer can't necessarily be modified atomically or
without locking, what we can do is prepare a buffer and then change a pointer so
that it points to our new buffer. All new readers will see the new data when
they dereference the pointer.</p>
<pre><code>                 Pointer
                 /     \
                /       \
           +---+        +----+
          /                   \
         /         -&gt;          \
        v                       v
       Old                      New
+---+---+---+---+        +---+---+---+---+
| 9 | 9 | 9 | 9 |        | 6 | 6 | 6 | 6 |
+---+---+---+---+        +---+---+---+---+
</code></pre>
<p>What do we do with the old pointer you might ask? Worry not, we will get into
that 😅</p>
<h3 id="the-descriptor-and-writedescriptor"><a class="header" href="#the-descriptor-and-writedescriptor">The Descriptor and WriteDescriptor</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct Descriptor&lt;'a, T: Sized&gt; {
    pending: AtomicPtr&lt;Option&lt;WriteDescriptor&lt;'a, T&gt;&gt;&gt;,
    size: usize,
}

pub struct WriteDescriptor&lt;'a, T: Sized&gt; {
    new: u64,
    old: u64,
    location: &amp;'a AtomicU64,
    _boo: PhantomData&lt;T&gt;, // New and old are transmuted T's
}
<span class="boring">}</span></code></pre></pre>
<h2 id="the-trait-bounds"><a class="header" href="#the-trait-bounds">The trait bounds</a></h2>
<p>Notice how T is <code>Sized</code>, this means that its size is always known at
compile-time. We need to ensure this because our values need to be transmutable.
Part of the safety contract of <code>transmute_copy</code> is making sure our types are of
compatible sizes.</p>
<p>The <code>Copy</code> bound is necessary because the data in the vector is copied in and
out of the buffers, with <code>transmute_copy</code>.</p>
<p>OK, enough talk about <code>struct</code>s, let's get to the first function: <code>get()</code></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="get"><a class="header" href="#get"><code>get()</code></a></h1>
<p>The first, and simplest function to write is <code>vector.get(i)</code>, which returns a
pointer to the element at index <em>i</em>.</p>
<p>Here is the code to that implements <code>get</code>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Return a *const T to the index specified
///
/// # Safety
/// The index this is called on **must** be a valid index, meaning:
/// there must already be a bucket allocated which would hold that index
/// **and** the index must already have been initialized with push/set
unsafe fn get(&amp;self, i: usize) -&gt; *const AtomicU64 {
    // Check for overflow
    let pos = i
        .checked_add(FIRST_BUCKET_SIZE)
        .expect(&quot;index too large, integer overflow&quot;);

    let hibit = highest_bit(pos);

    let offset = pos ^ (1 &lt;&lt; hibit);

    // Select the correct buffer to index into
    // # Safety
    // Since hibit = highest_bit(pos), and pos &gt;= FIRST_BUCKET_SIZE
    // The subtraction hibit - highest_bit(FIRST_BUCKET_SIZE) cannot underflow
    let buffer = &amp;self.buffers[(hibit - highest_bit(FIRST_BUCKET_SIZE)) as usize];

    // Check that the offset doesn't exceed isize::MAX
    assert!(
        offset
            .checked_mul(mem::size_of::&lt;T&gt;())
            .map(|val| val &lt; isize::MAX as usize)
            .is_some(),
        &quot;pointer offset exceed isize::MAX bytes&quot;
    );

    // Offset the pointer to return a pointer to the correct element
    unsafe {
        // # Safety
        // We know that we can offset the pointer because we will have allocated a
        // bucket to store the value. Since we only call values that are
        // `self.descriptor.size` or smaller, we know the offset will not go out of
        // bounds because of the assert.
        buffer.load(Ordering::Acquire).add(offset)
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="a-few-points-to-note"><a class="header" href="#a-few-points-to-note">A few points to note</a></h2>
<p>Notice how the function is marked as <code>unsafe</code>. This is because there is a
safety contract the compiler can't enforce: the index must be valid. This is
automatically guaranteed through the usage of the function in the algorithm, but
it's worth it marking it <code>unsafe</code> just to be explicit.</p>
<p>Summarizing what the function does, we calculate which buffer the item is in,
load the pointer to the start of the buffer, and offset it to the correct
element. There are two other things I want to point out. First, notice all the
checks we make to avoid overflow. Secondly, notice the use of <code>Acquire</code> for
loading in the pointer to the buffer. Since the store part of the
<code>compare_exchange(AcqRel)</code> we use to set the pointer to the buffer is <code>Release</code>,
we are guaranteed to get the most recent pointer, because an <code>Acquire</code> load sees
the contents <code>Release</code>ed by a <code>Release</code> store! I find it very satisfying how
<code>Acquire</code> and <code>Release</code> work together. It's like two puzzle pieces fitting
nicely into each other.</p>
<h2 id="what-are-all-these-bitwise-operations"><a class="header" href="#what-are-all-these-bitwise-operations">What are all these bitwise operations?</a></h2>
<p>I'm honestly not sure. That's why they wrote the paper and I didn't <code>:)</code>.</p>
<p>Next up is the <code>allocate_bucket</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="allocate_bucket"><a class="header" href="#allocate_bucket"><code>allocate_bucket()</code></a></h1>
<p>Remember that whole &quot;two-level array&quot; thingy? This is where it starts coming
into play. <code>allocate_bucket</code> does just what is sounds like: allocating a bucket.
Recall that a bucket is one of the arrays in the <em>second</em> level of the two level
array.</p>
<pre><code>+---+---+---+---+---+
| 1 | 2 | 3 | 4 | 5 |
+---+---+---+---+---+
  |   |   |   |   |
  v   v   v   v   v
+---+---+---+---+---+
| 1 | 2 | 3 | 4 | 5 |
+---+---+---+---+---+
    | 2 | 3 | 4 | 5 |
    +---+---+---+---+
        | 3 | 4 | 5 |
        +---+---+---+
          ^ | 4 | 5 |
          | +---+---+
          |     | 5 |
          |     +---+
          |
        we're allocating one of these little guys
</code></pre>
<p>There are two parts to <code>allocate_bucket</code>: allocating the memory and setting the
pointer. We start off by tapping into the <code>alloc</code> crate's API. First, we create
a <code>Layout</code>, which describes the allocation we want. The
<code>Layout::array::&lt;Atomic64&gt;()</code> indicates that we want a bunch of <code>AtomicU64</code>
right next to each other in memory. If creating the layout fails (due to
overflow), we call <code>capacity_overflow</code>, which just panics.</p>
<blockquote>
<p>You might ask, why not just directly call <code>panic!</code>? Apparently, it reduces the
generated code size if we just have panic in one function, which we then call
from multiple places. I found this trick in the source code for
<a href="https://github.com/rust-lang/rust/blob/master/library/alloc/src/raw_vec.rs#L512-L518"><code>std::vec::Vec</code></a>.
You can learn a <em>lot</em> from reading the Standard Library code. That's how I've
learned a lot of the low level stuff I know. It's also a good way to see what
good, idiomatic Rust looks like.</p>
</blockquote>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>const FIRST_BUCKET_SIZE: usize = 8;

fn allocate_bucket(&amp;self, bucket: usize) {
    // The shift-left is equivalent to raising 2 to the power of bucket
    let size = FIRST_BUCKET_SIZE * (1 &lt;&lt; bucket);
    let layout = match Layout::array::&lt;AtomicU64&gt;(size) {
        Ok(layout) =&gt; layout,
        Err(_) =&gt; capacity_overflow(),
    };

<span class="boring">}</span></code></pre></pre>
<p>The next thing we do is just another check. The Standard Library does both checks and I
trust their
<a href="https://github.com/rust-lang/rust/blob/master/library/alloc/src/raw_vec.rs#L176-L183">strategy</a>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Make sure allocation is ok
match alloc_guard(layout.size()) {
    Ok(_) =&gt; {}
    Err(_) =&gt; capacity_overflow(),
}

<span class="boring">}</span></code></pre></pre>
<blockquote>
<p><a href="https://github.com/rust-lang/miri"><code>Miri</code></a> is about to make its debut! <code>Miri</code>
is a tool that runs your code in a special environment and detects undefined
behavior (or UB, as the cool kids call it).</p>
</blockquote>
<p>Now that our layout is all good, we can perform the actual allocation. We
instantiate the <code>Global</code> <code>struct</code>, which is the allocator we're using. The
allocator returns a pointer to our new allocation once it's finished allocating.
Why are we using <code>allocated_zeroed</code> you might ask? Why not just allocate
normally? The answer: <em>It's Utmost Holiness:</em> <code>Miri</code>. In all seriousness though,
<code>Miri</code> has been and invaluable tool in catching memory and concurrency bugs.
When we just allocate normally, <code>Miri</code> throws and error when we start actually
using the memory later on, saying that
<code>intrinsics::atomic_cxchg_acqrel_failrelaxed(dst, old, new)</code> requires
initialized data. Thus, we just zero the memory for now. Later, it might be
worth it to do some <code>MaybeUninit</code> magic, but honestly, I don't know if there'll
be much, if any, performance gains.</p>
<p>Once again, we have more checks, and we'll just <code>panic!</code> if the allocation
fails. <code>handle_alloc_error</code> is from the <code>alloc</code> crate:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let allocator = Global;

let allocation = allocator.allocate_zeroed(layout);
let ptr = match allocation {
    Ok(ptr) =&gt; ptr.as_ptr() as *mut AtomicU64,
    Err(_) =&gt; handle_alloc_error(layout),
};

<span class="boring">}</span></code></pre></pre>
<p>The final part is to swap in the pointer into our array of buffers (the first
level of the two-level array). We use the <code>compare_exchange</code> function, with a
null pointer as the expected value, and our new pointer from the allocation. If
<code>compare_exchange</code> fails, that means the pointer is no longer null, and someone
else <code>compare_exchanged</code>ed in a pointer. Therefore, the bucket is already
allocated. In this case, we deallocate the freshly allocated memory. Notice how
we assess the result of <code>compare_exchange</code> with <code>Result::is_err()</code>; we don't
care about the value <code>compare_exchange</code> returns.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    if self.buffers[bucket] // &lt;- this is an AtomicPtr&lt;AtomicU64&gt;
        .compare_exchange(
            ptr::null_mut::&lt;AtomicU64&gt;(), // old value
            ptr, // new value
            Ordering::AcqRel, // ordering on success
            Ordering::Relaxed, // ordering on fail
        )
        .is_err()
    {
        unsafe {
            // # Safety
            // We know that the pointer returned from the allocation is NonNull so
            // we can call unwrap() on NonNull::new(). We also know that the pointer
            // is pointing to the correct memory because we just got it from the
            // allocation. We know the layout is valid, as it is the same layout we
            // used to allocate.
            allocator.deallocate(NonNull::new(ptr as *mut u8).unwrap(), layout);
        }
    }
}

<span class="boring">}</span></code></pre></pre>
<h2 id="success-and-fail-orderings"><a class="header" href="#success-and-fail-orderings">Success and Fail Orderings</a></h2>
<p>Like all atomic operations, <code>compare_exchange</code> uses the orderings. Most
operations take 1, but this bad boy takes two. Since <code>compare_exchange</code> reads
and writes a memory location, we're using <code>AcqRel</code>. Since we always use
<code>AcqRel</code> for the buckets, the load part (<code>Acquire</code>) of the <code>compare_exchange</code>
will always see the most recent value because the store part is <code>Release</code>. If we
just used <code>Acquire</code>, the store part of the <code>compare_exchange</code> would be
<code>Relaxed</code>, which doesn't guarantee that the modification to the
<code>AtomicPtr&lt;AtomicU64&gt;</code> is published to other threads by any certain point. Under
a <code>Relaxed</code> situation, another thread might load a null pointer in its
<code>compare_exchange</code>, even though our thread swapped in a pointer to memory!</p>
<p>That's the success ordering. The fail ordering is <code>Relaxed</code> because we don't
need to establish any synchronization if the operation fails. It failed; we're
not doing any stores. When I first saw this, I had the question, &quot;Why do we
provide different success and fail orderings if the <code>compare_exchange</code> doesn't
know if it will fail or not?&quot; The answer, thanks to Alice on the Rust User
Forums, is that the compiler picks an ordering that will always satisfy the stronger
ordering. Thus, <code>compare_exchange(success: AcqRel, fail: Release)</code> executes as
<code>compare_exchange(success: AcqRel, fail: Acquire)</code> to ensure that the initial
load is <code>Acquire</code> for both cases.</p>
<p>There's a little more to it; if you're still curious, see this
<a href="https://users.rust-lang.org/t/what-does-the-compare-exchange-fail-ordering-mean/75791">thread</a>
on the Rust User Forums.</p>
<p>The last function in the &quot;memory&quot; section is <code>reserve()</code>, which I've &quot;reserved&quot; for last.</p>
<hr />
<h3 id="complete-source-for-allocate_bucket"><a class="header" href="#complete-source-for-allocate_bucket">Complete source for <code>allocate_bucket()</code></a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn allocate_bucket(&amp;self, bucket: usize) {
    // The shift-left is equivalent to raising 2 to the power of bucket
    let size = FIRST_BUCKET_SIZE * (1 &lt;&lt; bucket);
    let layout = match Layout::array::&lt;AtomicU64&gt;(size) {
        Ok(layout) =&gt; layout,
        Err(_) =&gt; capacity_overflow(),
    };

    // Make sure allocation is ok
    match alloc_guard(layout.size()) {
        Ok(_) =&gt; {}
        Err(_) =&gt; capacity_overflow(),
    }

    let allocator = Global;
    // allocate_zeroed because miri complains about accessing uninitialized memory
    // TODO: Maybe use MaybeUninit?
    let allocation = allocator.allocate_zeroed(layout);
    let ptr = match allocation {
        Ok(ptr) =&gt; ptr.as_ptr() as *mut AtomicU64,
        Err(_) =&gt; handle_alloc_error(layout),
    };

    // If the CAS fails, then the bucket has already been initalized with memory
    // and we free the memory we just allocated
    if self.buffers[bucket]
        .compare_exchange(
            ptr::null_mut::&lt;AtomicU64&gt;(),
            ptr,
            Ordering::AcqRel,
            Ordering::Relaxed,
        )
        .is_err()
    {
        unsafe {
            // # Safety
            // We know that the pointer returned from the allocation is NonNull so
            // we can call unwrap() on NonNull::new(). We also know that the pointer
            // is pointing to the correct memory because we just got it from the
            // allocation. We know the layout is valid, as it is the same layout we
            // used to allocate.
            allocator.deallocate(NonNull::new(ptr as *mut u8).unwrap(), layout);
        }
    }
}

<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="reserve"><a class="header" href="#reserve"><code>reserve()</code></a></h1>
<p>The goal of <code>reserve(n)</code> is simple: allocate enough memory to perform <code>n</code> pushes
without allocating more memory.</p>
<p>This is a useful function, because, as we've seen, <code>allocate_bucket</code> requires
some heavy atomics with <code>compare_exchange</code>. If we can do our allocations in a
calmer scenario with less contention, we'll experience some performance gains.</p>
<p>We start by calculating the number of allocations we'll need to perform to
reserve enough space. The calculation is a little funky, and there's an edge
case where it can't distinguish between 0 and sizes between 1 and
<code>FIRST_BUCKET_SIZE</code>. That's why we need to explicitly allocate the first bucket.
We'll see the implementation of <code>size()</code> later, but it does use some atomic
synchronization, so we just cache the result so we can keep using it later
without calling <code>size</code> again.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn reserve(&amp;self, size: usize) {
    // Cache the size to prevent another atomic op from due to calling `size()` again
    let current_size = self.size();
    if current_size == 0 {
        self.allocate_bucket(0);
    }

<span class="boring">}</span></code></pre></pre>
<p>Now, we calculate the number of allocations we've made.</p>
<p><code>highest_bit</code> returns the highest set bit in a number. A bit is set
if it's equal to one. The highest set bit of 7 (<code>0b111</code>), for example, is 2
(0-indexed). Since the buckets are increasing by a factor of two each time, the
highest set bit of the indices in each bucket is one greater than the highest
set bit of the indices in the previous bucket. Therefore, by using the highest
bit of a number in conjunction with <code>FIRST_BUCKET_SIZE</code>, we can figure out how
many allocations are needed for a certain capacity. I know I'm waving my hands a
little; I haven't taken the time to rigorously understand the arithmetic, as
it's not that interesting to me, and in practice it works.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut num_current_allocs =
    highest_bit(current_size.saturating_add(FIRST_BUCKET_SIZE) - 1)
        .saturating_sub(highest_bit(FIRST_BUCKET_SIZE));

<span class="boring">}</span></code></pre></pre>
<p>Then we calculate the number of allocations we need to reserve the space, and
for each allocation missing, we allocate.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    // Compare with the number of allocations needed for size `new`
    while num_current_allocs
        &lt; highest_bit(size.saturating_add(FIRST_BUCKET_SIZE) - 1)
            .saturating_sub(highest_bit(FIRST_BUCKET_SIZE))
    {
        num_current_allocs += 1;
        self.allocate_bucket(num_current_allocs as usize);
    }
}

<span class="boring">}</span></code></pre></pre>
<p>And that's it for memory. We can now do every thing we need to do to access and
top up the vector's memory. Now's time for the really hard part: actually
implementing the vector's functions.</p>
<hr />
<h3 id="complete-source-for-reserve"><a class="header" href="#complete-source-for-reserve">Complete source for <code>reserve()</code></a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn reserve(&amp;self, size: usize) {
    // Cache the size to prevent another atomic op from due to calling `size()` again
    let current_size = self.size();
    if current_size == 0 {
        self.allocate_bucket(0);
    }

    // Number of allocations needed for current size
    let mut num_current_allocs =
        highest_bit(current_size.saturating_add(FIRST_BUCKET_SIZE) - 1)
            .saturating_sub(highest_bit(FIRST_BUCKET_SIZE));

    // Compare with the number of allocations needed for size `new`
    while num_current_allocs
        &lt; highest_bit(size.saturating_add(FIRST_BUCKET_SIZE) - 1)
            .saturating_sub(highest_bit(FIRST_BUCKET_SIZE))
    {
        num_current_allocs += 1;
        self.allocate_bucket(num_current_allocs as usize);
    }
}

<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="operations"><a class="header" href="#operations">Operations</a></h1>
<p>Now that we have a solid memory backbone, we're going to implement the public
API of the vector: <code>new</code>, <code>push</code>, <code>pop</code>, and <code>size</code>, as well as <code>complete_write</code>
and some helper functions.</p>
<p>Since it's been a little bit, here's what the vector look like in code form again:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct SecVec&lt;'a, T: Sized + Copy&gt; {
    buffers: CachePadded&lt;Box&lt;[AtomicPtr&lt;AtomicU64&gt;; 60]&gt;&gt;,
    descriptor: CachePadded&lt;AtomicPtr&lt;Descriptor&lt;'a, T&gt;&gt;&gt;,
    _boo: PhantomData&lt;T&gt;, // Data is stored as transmuted T's
}

struct Descriptor&lt;'a, T: Sized&gt; {
    pending: AtomicPtr&lt;Option&lt;WriteDescriptor&lt;'a, T&gt;&gt;&gt;,
    size: usize,
}

struct WriteDescriptor&lt;'a, T: Sized&gt; {
    new: u64,
    old: u64,
    location: &amp;'a AtomicU64,
    _boo: PhantomData&lt;T&gt;, // New and old are transmuted T's
}

<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="new"><a class="header" href="#new"><code>new()</code></a></h1>
<p>We've got to have some way of making a vector (or at least for an outside user
to make one).</p>
<p>What are the ingredients we need to make the vector? Buffers, <code>Descriptor</code>, and
<code>WriteDescriptor</code>. The <code>WriteDescriptor</code> is going to be <code>None</code>, as we don't have
any pending writes yet.</p>
<p>Here's the code:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// We actually do want this to be copied
#[allow(clippy::declare_interior_mutable_const)]
const ATOMIC_NULLPTR: AtomicPtr&lt;AtomicU64&gt;
    = AtomicPtr::new(ptr::null_mut::&lt;AtomicU64&gt;());

pub fn new() -&gt; Self {
    // Make an array of 60 AtomicPtr&lt;Atomicu64&gt; set to the null pointer
    let buffers = Box::new([ATOMIC_NULLPTR; 60]);

    // Make a new WriteDescriptor
    let pending = WriteDescriptor::&lt;T&gt;::new_none_as_ptr();

    // Make a new descriptor
    let descriptor = Descriptor::&lt;T&gt;::new_as_ptr(pending, 0, 0);

    // Return self
    Self {
        descriptor: CachePadded::new(AtomicPtr::new(descriptor)),
        buffers: CachePadded::new(buffers),
        _boo: PhantomData,
    }
}

<span class="boring">}</span></code></pre></pre>
<p>Firstly, we declare the constant <code>ATOMIC_NULLPTR</code>. This is just an <code>AtomicPtr</code>
containging a null pointer. The reason the <code>const</code> declaration is necessary is
that when we make an array of something <code>[SOMETHING; 60]</code>, that <code>SOMETHING</code>
needs to be <code>Copy</code> or evaluatable at compile time. Since <code>AtomicPtr&lt;AtomicU64&gt;</code>
is not <code>Copy</code>, we resort to creating <code>ATOMIC_NULLPTR</code> at compile time. Once we
have our array of null pointers, we put it on the heap to reduce the size of the
vector. If we were carrying it all directly, the vector would be over 480 bytes
large! With a <code>Box</code>, we only store 8 bytes pointing to the first level in our
two-level array.</p>
<p>Then, we make a <code>WriteDescriptor</code> using <code>new_none_as_ptr()</code>, which returns an
<code>Option&lt;WriteDescriptor&lt;T&gt;&gt;</code>. We pass this into the constructor (<code>new_as_ptr</code>)
for <code>Descriptor&lt;T&gt;</code>, and then assemble the <code>Descriptor</code> and the <code>Box</code>ed array
together to make the vector.</p>
<p>The constructors for the descriptor types end in <code>as_ptr</code> because they actually
return a raw pointer pointing to a heap allocation containing the value. We
achieve this by making a <code>Box</code> and then extracting the inner raw pointer.</p>
<pre><code>let b = Box::(5);
let b_ptr = Box::into_raw(b); &lt;- That's a raw pointer to heap memory!
</code></pre>
<h2 id="my-first-ub-mistake"><a class="header" href="#my-first-ub-mistake">My first UB mistake</a></h2>
<p>I introduced the heap and the stack earlier in the keywords section, but I
didn't explain why the distinction is important.</p>
<p>When a function is called, a <em>stack frame</em> is pushed onto the stack. This stack
frame contains all the function's local variables. When the function returns,
the stack frame is popped off the stack, and all local variables are destroyed.
This invalidates all references to local variables that were just popped off.</p>
<p>The heap is different. You allocate on the heap, and you deallocate on the heap.
Nothing happens automatically. This is the legendary <code>malloc/free</code> combo from
<code>C</code>.</p>
<p>Understanding the distinction between the stack and the heap is important
because we are using raw pointers, which don't have the guarantees of
references.</p>
<p>Here is my first mistake, summarized a little:</p>
<pre><pre class="playground"><code class="language-rust">use core::sync::atomic::{Ordering, AtomicPtr};

fn main() {
    let ptr = new_descriptor();
    // Use the pointer to the Descriptor
    let d = unsafe { &amp;*ptr.load(Ordering::Acquire) };
}

// Return a pointer to a Descriptor
fn new_descriptor() -&gt; AtomicPtr&lt;Descriptor&gt; {
    let d = Descriptor { size: 0, write: None };
    AtomicPtr::new(&amp;d as *const _ as *mut _)
}

struct Descriptor {
    size: usize,
    write: Option&lt;bool&gt;
}
</code></pre></pre>
<pre><code>$ cargo miri run
</code></pre>
<pre><code>error: Undefined Behavior: pointer to alloc1184 was dereferenced after this allocation got freed
  --&gt; src\main.rs:46:22
   |
46 |     let d = unsafe { &amp;*ptr.load(Ordering::Acquire) };
   |                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ pointer to alloc1184 was dereferenced after this allocation got freed
   |
   = help: this indicates a bug in the program: it performed an invalid operation, and caused Undefined Behavior
</code></pre>
<p><code>Miri</code> says
<code>pointer to alloc1184 was dereferenced after this allocation got freed</code>.
Translation: <code>use-after-free</code>; classic UB.</p>
<p>So why is the <code>Descriptor</code>'s allocation being freed? Because it's <strong>allocated on
the stack</strong>. When <code>new_descriptor</code> returns, the local variable <code>d: Descriptor</code>
get's destroyed, and the pointer we made from the reference is invalidated.
Thus, we <code>use-after-free</code> when we deference a freed allocation.</p>
<p>This is the danger of using raw pointers. If we just passed on the reference
<code>Descriptor</code>, <code>Rust</code> would
<a href="https://rust-lang.github.io/rfcs/3027-infallible-promotion.html">promote</a> that
value to have a <code>'static</code> lifetime if possible, or return an error if not. With
raw pointers, <code>Rust</code> doesn't manage lifetimes, so we have to ensure that our
pointers are valid.</p>
<p>This is why only dereferencing a raw pointer is <code>unsafe</code>. It's perfectly safe to
make one, but we have no guarantees about what it's pointing to, and that's why
the dereference is <code>unsafe</code>.</p>
<p>Thank you <code>Miri</code>!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="complete_write-1"><a class="header" href="#complete_write-1"><code>complete_write()</code></a></h1>
<p>I think <code>complete_write</code> is the first function I wrote for the vector's core
operations. We execute the <code>WriteDescriptor</code> passed in and set the one stored in
the vector to <code>None</code></p>
<p>Here's what the function signature looks like:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn complete_write(&amp;self, pending: &amp;Option&lt;WriteDescriptor&lt;T&gt;&gt;) {

<span class="boring">}</span></code></pre></pre>
<p>The first thing we do is execute the <code>WriteDescriptor</code>, if there is one. We can
use <code>if let</code> syntax to concisely express this. The result of the
<code>compare_exchange</code> doesn't matter. If it succeeds, we performed the write. If it
doesn't, someone else performed it. Also, notice how we are
<code>compare_exchange</code>ing an <code>AtomicU64</code>. The data is transmuted into those bytes,
allowing us to make atomic modifications to the contents of the vector. Because
the data needs to be transmuted into an atomic type, the vector can't support
types larger than 8 bytes. Finally, because we are using <code>AcqRel</code> as the success
ordering, any subsequent <code>Acquire</code> loads will see the that there is no pending
write.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    #[allow(unused_must_use)]
    if let Some(writedesc) = pending {
        AtomicU64::compare_exchange(
            writedesc.location,
            writedesc.old,
            writedesc.new,
            Ordering::AcqRel,
            Ordering::Relaxed,
        );

<span class="boring">}</span></code></pre></pre>
<p>Now that we've done the store to the contents, we change the <code>WriteDescriptor</code>
status of the vector to indicate that there is no pending write (we just took
care of it!).</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>        let new_writedesc = WriteDescriptor::&lt;T&gt;::new_none_as_ptr();
        // # Safety
        // The pointer is valid to dereference because it started off valid
        // and only pointers made from WriteDescriptor::new_*_as_ptr()
        // (which are valid because of Box) are CAS'd in
        unsafe { &amp;*self.descriptor.load(Ordering::Acquire) } // Loading with `Acquire`
            .pending
            .store(new_writedesc, Ordering::Release); // Storing with `Release`

        // Memory leak alert!
        // What happens to the old pointer stored in the
        // `AtomicPtr&lt;Option&lt;WriteDescriptor&lt;T&gt;&gt;&gt;`?
        // We never reclaim it.
    }
}

<span class="boring">}</span></code></pre></pre>
<p>This is standard. We make a new <code>WriteDescriptor</code> and store it with <code>Release</code> so
that all subsequent <code>Acquire</code> loads will see it.</p>
<h2 id="leaking-memory"><a class="header" href="#leaking-memory">Leaking memory</a></h2>
<p>Leaking memory is when you use memory (allocating) but never free it. This is
the first chunk of code that leaks. Our <code>Descriptor</code> has a pointer to an
<code>Option&lt;WriteDescriptor&gt;</code>. When we store a different pointer, we lose the old
pointer forever. Since we never do anything to deallocate the memory pointed to
by the old pointer, like <code>Box::from_raw</code>, that memory will stay allocated until
the end of the program.</p>
<p>We can't just directly free the memory right away though, as there could be
another thread reading it. Later on, I'm going to show you how we can use a
technique called <em>hazard pointers</em> to safely reclaim (deallocate) objects.</p>
<p>For now, the vector will stay leaky, and we'll move on the <code>push</code>.</p>
<hr />
<h3 id="complete-source-for-complete_write"><a class="header" href="#complete-source-for-complete_write">Complete source for <code>complete_write()</code></a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn complete_write(&amp;self, pending: &amp;Option&lt;WriteDescriptor&lt;T&gt;&gt;) {
    #[allow(unused_must_use)]
    if let Some(writedesc) = pending {
        AtomicU64::compare_exchange(
            writedesc.location,
            writedesc.old,
            writedesc.new,
            Ordering::AcqRel,
            Ordering::Relaxed,
        );
        let new_writedesc = WriteDescriptor::&lt;T&gt;::new_none_as_ptr();
        // # Safety
        // The pointer is valid to dereference because it started off valid
        // and only pointers made from WriteDescriptor::new_*_as_ptr()
        // (which are valid because of Box) are CAS'd in
        unsafe { &amp;*self.descriptor.load(Ordering::Acquire) }
            .pending
            .store(new_writedesc, Ordering::Release);
    }
}

<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="push-1"><a class="header" href="#push-1"><code>push()</code></a></h1>
<p>You made it! We're going to implement half of the main functionality of the
vector. The code is going to get a little complex, but I'm confident in you. I
eventually understood what was going on, so you can too.</p>
<p>We're going to track the steps described in
<a href="code/ops/../../paper/algorithm.html"><strong>The Algorithm</strong></a> closely. We don't want to mess up
the concurrent semantics of the vector during implementation. The first thing we
do is load in the <code>Descriptor</code> and <code>WriteDescriptor</code>. This is actually harder
than it might seem, as we're working with <code>unsafe</code> things like raw pointers. We
need to be very careful. But wait, there's one more thing we should cover, and
that's <em>exponential backoff</em>!</p>
<h2 id="exponential-backoff"><a class="header" href="#exponential-backoff">Exponential Backoff</a></h2>
<p>Exponential backoff is another one of those techniques that's unique to
concurrent programming. <code>compare_exchange</code> algorithms like the one we're
implementing can produce a lot of contention over a couple specific memory
locations. For example, may threads are trying to <code>compare_exchange</code> the
<code>AtomicPtr&lt;Descriptor&gt;</code> stored in the vector. That spot in memory is constantly
bombarded with heavy atomic operations. One way we can alleviate this is by
waiting a little bit after failing to <code>compare_exchange</code>. The first time we
fail, we back off for <code>1</code> tick. If we fail again, we back off for <code>2</code> ticks,
then <code>4</code>, <code>8</code> . . . this is why the <em>backoff</em> is <em>exponential</em>. By backing off,
we give another thread some room to successfully perform their
<code>compare_exchange</code>. In some mircobenchmarks I did, introducing exponential
backoff greatly speeded up the vector. It's cool that going slower at a micro
level allows us to go faster on a macro level. <code>crossbeam_utils</code> has a useful
little <code>struct</code> called <code>Backoff</code> that we're going to use.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn push(&amp;self, elem: T) {
    let backoff = Backoff::new(); // Backoff causes significant speedup
    loop {
        // # Safety
        // It is safe to dereference the raw pointers because they started off valid
        // and can only be CAS'd with pointers from `Box::into_raw`
        let current_desc = unsafe { &amp;*self.descriptor.load(Ordering::Acquire) };

        // Complete a pending write op if there is any
        let pending = unsafe { &amp;*current_desc.pending.load(Ordering::Acquire) };

<span class="boring">}</span></code></pre></pre>
<p>There is already a lot going on here, in just these 10ish lines of code.
Firstly, we've instantiated a <code>Backoff</code>. A the bottom of the loop, if we failed
to <code>compare_exchange</code> in our new <code>Descriptor</code>, we'll call <code>Backoff::spin()</code> to
wait a little bit, then we'll come back up to the top of the loop and try again.</p>
<p>This code also contains a very <code>unsafe</code> operation: dereferencing a raw pointer.
The more I read about the dangers of raw pointers, the more scared I got.
Paraphrasing from
<a href="https://doc.rust-lang.org/book/ch19-01-unsafe-rust.html?highlight=raw%20pointer#dereferencing-a-raw-pointer">The Book</a>,
raw pointers aren't guaranteed to point to valid memory, aren't guaranteed to be
non-null, don't implement cleanup (like <code>Box</code>), and ignore all the aliasing
rules (<code>&amp;/&amp;mut</code> semantics).</p>
<p>After watching
<a href="https://www.youtube.com/watch?v=QAz-maaH0KM">Demystifying <code>unsafe</code> code</a> I felt
better. <code>unsafe</code> code isn't intrinsically bad, it's just code that comes with an
extra contract that we must uphold and document.</p>
<p>In the case of these first raw pointer dereferences, we know the dereference is
safe because the pointers to the <code>Descriptor</code> and <code>WriteDescriptor</code> come from
<code>Box::into_raw</code>, which returns a non-null and aligned pointer. <code>unsafe</code> is
scary, but not necessarily bad. Obviously, we should try to limit its uses as
much as possible though, as we can slip up and violate contracts.</p>
<blockquote>
<p>Mitigating <code>unsafe</code> code: there are ways we can construct API's that need
<code>unsafe</code> code to work without exposing users to danger. For example, we could
make a type <code>AtomicBox&lt;T&gt;</code> that's mostly a wrapper around <code>AtomicPtr&lt;T&gt;</code>. It
might look a little something like this:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[repr(transparent)]
struct AtomicBox&lt;T&gt; {
    ptr: AtomicPtr&lt;T&gt;
}

impl&lt;T&gt; AtomicBox&lt;T&gt; {
    // We can only make a `Self` from a `Box`'s pointer!
    pub fn new(box: Box&lt;T&gt;) -&gt; Self {
        AtomicPtr::new(Box::into_raw(box))
    }

    // Caller knows they are receiving a pointer from `Box`
    pub fn load(&amp;self, ordering: Ordering) -&gt; *mut T {
        self.0.load(ordering)
    }

    // -- snip --
}

<span class="boring">}</span></code></pre></pre>
<p>There's nothing super crazy going on here, it's just that we've configured the
API so that we <strong>know</strong> the pointer inside the <code>AtomicBox&lt;T&gt;</code> is valid because
it could only have come from <code>Box</code>. Now, instead of manually ensuring the
invariant that we use <code>Box::into_raw</code> pointers, the compiler/type system does
so for us.</p>
</blockquote>
<p>After loading in the <code>WriteDescriptor</code>, we execute it if need be.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    self.complete_write(pending);

<span class="boring">}</span></code></pre></pre>
<p>Since we're <code>push</code>ing onto the vector, we might need more memory:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    // Calculate which bucket this element is going into
    let bucket = (highest_bit(current_desc.size + FIRST_BUCKET_SIZE)
        - highest_bit(FIRST_BUCKET_SIZE)) as usize;

    // If the bucket is null, allocate the memory
    if self.buffers[bucket].load(Ordering::Acquire).is_null() {
        self.allocate_bucket(bucket)
    }

<span class="boring">}</span></code></pre></pre>
<p>Let's make our new <code>WriteDescriptor</code> now:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    // # Safety
    // It is safe to call `self.get()` because if the vector has reached
    // `current_desc.size`, so there is a bucket allocated for element `size`.
    // Therefore, the pointer is also valid to dereference because it points
    // into properly allocated memory.
    let last_elem = unsafe { &amp;*self.get(current_desc.size) };
    let write_desc = WriteDescriptor::&lt;T&gt;::new_some_as_ptr(
        unsafe { mem::transmute_copy::&lt;T, u64&gt;(&amp;elem) },
        // Load from the AtomicU64, which really contains the bytes for T
        last_elem.load(Ordering::Acquire),
        last_elem,
    );

<span class="boring">}</span></code></pre></pre>
<p>For now we are assuming that the vector is only storing values 8 bytes big,
therefore it is safe to <code>transmute_copy</code> to an <code>AtomicU64</code>. I plan on writing a
macro that produces different implementations of the vector with different
atomic types when storing types of different sizes. For example,
<code>SecVec&lt;(i8, i8)&gt;</code> would store the data in <code>AtomicU16</code>. This would save on
space. I don't think the vector would work for zero-sized types because of how
we <code>transmute</code>. It would also be very inefficient because of all the unnecessary
allocations!</p>
<p>Note that <code>last_elem</code>'s type is <code>&amp;AtomicU64</code>; it's the location of the write.
When we load from <code>last_elem</code>, we are getting the <code>old</code> element. We now have the
three pieces of data necessary for <code>compare_exchange</code>: a memory location (the
reference), an old element, and a new element (the <code>T</code> passed to this function).</p>
<p>Let's package everything up in a <code>Descriptor</code>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    let next_desc = Descriptor::&lt;T&gt;::new_as_ptr(write_desc, current_desc.size + 1);

<span class="boring">}</span></code></pre></pre>
<p>Since we are adding one more element onto the vector, the new <code>Descriptor</code>'s
size is one more than the old one's.</p>
<p>Here comes the crucial <code>compare_exchange</code>, in the <code>AcqRel/Relaxed</code> flavor:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    if AtomicPtr::compare_exchange_weak(
        &amp;self.descriptor,
        current_desc as *const _ as *mut _,
        next_desc,
        Ordering::AcqRel,
        Ordering::Relaxed,
    )
    .is_ok()
    {
        // We know the current write_desc is the one we just sent in
        // with the compare_exchange so avoid loading it atomically
        self.complete_write(unsafe { &amp;*write_desc });
        break;
    }

<span class="boring">}</span></code></pre></pre>
<p>If the <code>compare_exchange</code> succeeds, we call <code>complete_write</code> on the descriptor
we just made to finalize the changes, then we <code>break</code> out of the loop.</p>
<p>If <code>compare_exchange</code> fails, we'll simply start over again.</p>
<p>Either way, <strong>we have a memory leak</strong>. If the <code>compare_exchange</code> succeeded, we
never deal with the old <code>Descriptor</code>'s pointer. We can never safely deallocate
it because we don't know if anyone is reading it. It would be terribly rude to
pull the rug out from under them! Also the deallocation would probably cause a
<code>use-after-free</code> which would cause the OS to terminate the program which would
rip a hole in the space-time continuum which would. Wait what? Uhh, moving on .
. .</p>
<p>If the <code>compare_exchange</code> failed, the new <code>Descriptor</code> and <code>WriteDescriptor</code>
leak. Once we reach the end of the loop, all local variables in that scope are
lost. So, we never get back the pointers to our new describe-y objects, and
their memory is lost the the void, never to be seen again (unless we do some
wildly dumb stuff and read a random address or something). In any case, within
the code for the vector, I try not to tempt the segfault gods. My other
projects, maybe a little bit.</p>
<p>At this point, we've failed the <code>compare_exchange</code>. Let's <code>Backoff::spin()</code> and
then retry:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>        backoff.spin();
    } // Closing brace for the loop
} // Closing brace for the function

<span class="boring">}</span></code></pre></pre>
<p>Once we finish looping and finally succeed with the <code>compare_exchange</code>, we're
done! That's a <code>push</code>. The pseudocode is so simple, and the code is so . . . not
simple. Props to you for getting this far, concurrent programming is not for the
weak of spirit.</p>
<p>I'll cover the minor differences in <code>pop</code>, and then we'll cap off the leaky code
with <code>size</code>.</p>
<hr />
<h3 id="complete-source-for-push"><a class="header" href="#complete-source-for-push">Complete source for <code>push</code></a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn push(&amp;self, elem: T) {
    let backoff = Backoff::new(); // Backoff causes significant speedup
    loop {
        // # Safety
        // It is safe to dereference the raw pointers because they started off valid
        // and can only be CAS'd with pointers from `Box::into_raw`
        let current_desc = unsafe { &amp;*self.descriptor.load(Ordering::Acquire) };
        let pending = unsafe { &amp;*current_desc.pending.load(Ordering::Acquire) };

        // Complete a pending write op if there is any
        self.complete_write(pending);

        // Allocate memory if need be
        let bucket = (highest_bit(current_desc.size + FIRST_BUCKET_SIZE)
            - highest_bit(FIRST_BUCKET_SIZE)) as usize;
        if self.buffers[bucket].load(Ordering::Acquire).is_null() {
            self.allocate_bucket(bucket)
        }
        // # Safety
        // It is safe to call `self.get()` because if the vector has reached
        // `current_desc.size`, so there is a bucket allocated for element `size`.
        // Therefore, the pointer is also valid to dereference because it points
        // into properly allocated memory.
        let last_elem = unsafe { &amp;*self.get(current_desc.size) };

        let write_desc = WriteDescriptor::&lt;T&gt;::new_some_as_ptr(
            unsafe { mem::transmute_copy::&lt;T, u64&gt;(&amp;elem) },
            last_elem.load(Ordering::Acquire),
            last_elem,
        );

        let next_desc = Descriptor::&lt;T&gt;::new_as_ptr(write_desc, current_desc.size + 1);

        // Handle result of compare_exchange
        if AtomicPtr::compare_exchange_weak(
            &amp;self.descriptor,
            current_desc as *const _ as *mut _,
            next_desc,
            Ordering::AcqRel,
            Ordering::Relaxed,
        )
        .is_ok()
        {
            // We know the current write_desc is the one we just sent in
            // with the compare_exchange so avoid loading it atomically
            self.complete_write(unsafe { &amp;*write_desc });
            break;
        }

        backoff.spin();
    }
}

<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="pop"><a class="header" href="#pop">pop</a></h1>
<p>There are three main differences between <code>pop</code> and <code>push</code>. Firstly, <code>pop</code> never
needs to allocate. Secondly, <code>pop</code> swaps in a slightly different descriptor,
with <code>None</code> as the <code>WriteDescriptor</code> and <code>current_desc.size - 1</code> as the new
size.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    let new_pending = WriteDescriptor::&lt;T&gt;::new_none_as_ptr();
    let next_desc = Descriptor::&lt;T&gt;::new_as_ptr(new_pending, current_desc.size - 1);

<span class="boring">}</span></code></pre></pre>
<p>The final difference is that after we succeed with the <code>compare_exchange</code>, we
read the last element and return it.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    if AtomicPtr::compare_exchange_weak(
        &amp;self.descriptor,
        current_desc as *const _ as *mut _,
        next_desc,
        Ordering::AcqRel,
        Ordering::Relaxed,
    )
    .is_ok()
    {
        // # Safety
        // This is ok because only 64-bit values can be stored in the vector
        // We also know that elem is a valid T because it was transmuted into a usize
        // from a valid T, therefore we are only transmuting it back
        return Some(unsafe { mem::transmute_copy::&lt;u64, T&gt;(&amp;elem) });
    }

<span class="boring">}</span></code></pre></pre>
<p>The rest of the function: loading the <code>Descriptors</code>, <code>compare_exchange</code>,
<code>Backoff</code>, is identical.</p>
<p>Like <code>push</code>, <code>pop</code> also leaks memory profusely. Luckily, this means that when we
implement memory reclamation, it'll be the same solution for <code>push</code> and <code>pop</code>.</p>
<hr />
<h3 id="complete-source-for-pop"><a class="header" href="#complete-source-for-pop">Complete source for <code>pop()</code></a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn pop(&amp;self) -&gt; Option&lt;T&gt; {
    let backoff = Backoff::new(); // Backoff causes significant speedup
    loop {
        let current_desc = unsafe { &amp;*self.descriptor.load(Ordering::Acquire) };
        let pending = unsafe { &amp;*current_desc.pending.load(Ordering::Acquire) };

        self.complete_write(pending);
        if current_desc.size == 0 {
            return None;
        }

        // # Safety
        // Do not need to worry about underflow for the sub because we would have
        // already returned
        let elem = unsafe { &amp;*self.get(current_desc.size - 1) }
            .load(Ordering::Acquire);

        let write_desc = WriteDescriptor::&lt;T&gt;::new_none_as_ptr();
        let next_desc = Descriptor::&lt;T&gt;::new_as_ptr(write_desc, current_desc.size - 1);

        if AtomicPtr::compare_exchange_weak(
            &amp;self.descriptor,
            current_desc as *const _ as *mut _,
            next_desc,
            Ordering::AcqRel,
            Ordering::Relaxed,
        )
        .is_ok()
        {
            // # Safety
            // This is ok because only 64-bit values can be stored in the vector
            // We also know that elem is a valid T because it was transmuted into a
            // usize from a valid T, therefore we are only transmuting it back
            return Some(unsafe { mem::transmute_copy::&lt;u64, T&gt;(&amp;elem) });
        }
        backoff.spin();
    }
}

<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="size"><a class="header" href="#size"><code>size()</code></a></h1>
<p>The procedure for <code>size</code> is simple. Load the vector's size from the
<code>Descriptor</code>, then subtract one if there is a pending write.</p>
<p>It seems like so long ago that we went over
<a href="code/ops/../../paper/algorithm.html">The Algorithm</a>, but recall that when we perform a
<code>push</code>, we swap in a <code>Descriptor</code>, then call <code>complete_write</code>. This means that
when we do a write, the increase in size is reflected in the vector's state
before the write actually happens. If there is still a <code>WriteDescriptor</code>
contained in the <code>Descriptor</code>, that means the size stored in the <code>Descriptor</code> is
one greater than the actual size of the vector, because <code>complete_write</code>
replaces the <code>WriteDescriptor</code> with <code>None</code> when it executes the write.</p>
<p>Here is the code:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn size(&amp;self) -&gt; usize {
    // # Safety
    // The pointers are safe to dereference because they all came from `Box::into_raw`
    // and point to valid objects

    let desc = unsafe { &amp;*self.descriptor.load(Ordering::Acquire) };
    let size = desc.size;

    // If there is a pending descriptor, we subtract one from the size because
    // `push` increments the size, swaps the new descriptor in, and _then_ writes
    // the value. Therefore the size is one greater because the write hasn't happened
    // yet
    match unsafe { &amp;*desc.pending.load(Ordering::Acquire) } {
        Some(_) =&gt; size - 1,
        None =&gt; size,
    }
}
<span class="boring">}</span></code></pre></pre>
<p>There have been many momentous moments throughout the book: understanding the
algorithm, finishing <code>push</code>, and finally, completing the vector's public API.
When I was writing the code, this moment felt huge, and I jumped up and down
after <code>push</code>ing 10 elements onto the vector, <code>pop</code>ing 10 times, and running
<code>assert_eq!(sv.size(), 0);</code> withough crashing.</p>
<p>Let's run some tests (more fun than you might think)!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tests"><a class="header" href="#tests">Tests</a></h1>
<p>Just for fun, I wrote some tests, and we get to satisfyingly see them pass.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn size_starts_at_0() {
        let sv = SecVec::&lt;usize&gt;::new();
        assert_eq!(0, sv.size());
    }

    #[test]
    fn pop_empty_returns_none() {
        let sv = SecVec::&lt;usize&gt;::new();
        assert_eq!(sv.pop(), None);
    }

    #[test]
    fn ten_push_ten_pop() {
        let sv = SecVec::&lt;isize&gt;::new();
        for i in 0..10 {
            sv.push(i);
        }
        for i in (0..10).rev() {
            assert_eq!(sv.pop(), Some(i));
        }
    }

    #[test]
    fn does_not_allocate_buffers_on_new() {
        let sv = SecVec::&lt;isize&gt;::new();
        for buffer in &amp;**sv.buffers {
            assert!(buffer.load(Ordering::Relaxed).is_null())
        }
    }
}

<span class="boring">}</span></code></pre></pre>
<p><code>Cargo</code> is super nice and we can use it to test. Running <code>cargo test</code> produces
the following output:</p>
<pre><code>~/C/r/unlocked (main) &gt; cargo test -- leaky::tests
    Finished test [unoptimized + debuginfo] target(s) in 0.01s
     Running unittests (target/debug/deps/unlocked-e6f64e7ba9c7e004)

running 4 tests
test leaky::tests::size_starts_at_0 ... ok
test leaky::tests::pop_empty_returns_none ... ok
test leaky::tests::does_not_allocate_buffers_on_new ... ok
test leaky::tests::ten_push_ten_pop ... ok
</code></pre>
<p>Although you can't see it, the green on those &quot;ok&quot;s warms my heart.</p>
<p>We know the vector is leaky, but otherwise it shouldn't be doing any other funky
things or UB. Let's see if <code>Miri</code> finds anything with
<code>MIRIFLAGS=-Zmiri-ignore-leaks cargo miri test -- leaky::tests</code>:</p>
<pre><code>~/C/r/unlocked (main) &gt; MIRIFLAGS=-Zmiri-ignore-leaks cargo miri test -- leaky::tests
    Finished test [unoptimized + debuginfo] target(s) in 0.01s
     Running unittests (target/miri/x86_64-apple-darwin/debug/deps/unlocked-4269)

running 4 tests
test leaky::tests::does_not_allocate_buffers_on_new ... ok
test leaky::tests::pop_empty_returns_none ... ok
test leaky::tests::size_starts_at_0 ... ok
test leaky::tests::ten_push_ten_pop ... ok
</code></pre>
<p>Nothing? Awesome! Just because <code>Miri</code> doesn't find anything doesn't mean nothing
fishy is happening. <code>Miri</code> combined with the rigorous analysis of the code we
did though is a very good sign.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="memory-reclamation"><a class="header" href="#memory-reclamation">Memory Reclamation</a></h1>
<p>Allocation isn't the hard part when it comes to concurrency,
deallocation/reclamation is. When multiple threads/entities are concurrently
accessing an object, it is <strong>never</strong> safe to deallocate it without verifying
that no one has a reference/pointer to it. What if they were to use that pointer
after the deallocation?</p>
<p>This problem arises in the vector when reclaiming the <code>Descriptor</code>s and
<code>WriteDescriptors</code>. Multiple threads can hold a reference to them at once, so we
never know when it is safe to deallocation.</p>
<p>To solve this problem, we'll used technique called <em>hazard pointers</em> via the
<a href="https://docs.rs/haphazard/latest/haphazard"><code>haphazard</code></a> crate.</p>
<blockquote>
<p>What is meant by reclamation/deallocation? When we allocate memory, the
allocator returns a pointer to an allocation on the heap. Internally, the
allocator also notes down that the space is being used. When we deallocate, or
reclaim, memory, we return the pointer back to the allocator. The allocator
goes back to the books and notes that no one is using the memory anymore,
<em>freeing</em> the memory. It can now hand that memory back out again if it's
needed.</p>
</blockquote>
<p>I'm not sure if this is the case, but I think the term &quot;reclaim&quot; might be used
specifically in concurrent contexts. Rust automatically deallocates memory in
single-threaded contexts using the borrow checker. We have to do everything
manually in multithreaded contexts</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="hazard-pointers"><a class="header" href="#hazard-pointers">Hazard Pointers</a></h1>
<p>The idea of hazard pointers is to <em>protect</em> memory addresses from reclamation.
At any moment in time, we have a list of addresses that are not safe to reclaim.
We can store the addresses in a data structure like a concurrent linked list; I
think this is what <code>haphazard</code>
<a href="https://docs.rs/haphazard/latest/src/haphazard/domain.rs.html#759-768">uses</a>.</p>
<p>Whenever we want to access a pointer, we access it through a <em>hazard pointer</em>.
Accessing through a hazard pointer adds the address we are accessing to the list
of addresses to protect. When the hazard pointer gets dropped, or we explicitly
disassociate the hazard pointer from the underlying raw pointer, the protection
ends.</p>
<p>So why is the <code>Protected</code> list important? When we are done with an object, we
<em>retire</em> it, marking it for eventual reclamation. By retiring the pointer, we
agree to not use it anymore. Any thread that is already accessing it can
continue to do so, but there can be no <em>new</em> readers/writers.</p>
<p>Every once in a while, the <code>Domain</code>, which holds the hazard pointers, will go
through the <code>Retired</code> list. For each pointer on this list, the <code>Domain</code> checks
whether the pointer is protected by reading the <code>Protected</code> list. If the pointer
isn't protected, the <code>Domain</code> reclaims the object it points to (deallocating the
pointer). If it is protected, the <code>Domain</code> does not reclaim it, because someone
is using it. In this way, we prevent pointers in use from being deallocated, but
those out of use are deallocated.</p>
<h2 id="an-example"><a class="header" href="#an-example">An example</a></h2>
<p>Hazard pointers are pretty complicated, so here's a visual example that I hope
helps:</p>
<pre><code>Protected: [1&lt;0x22&gt;]
Retired: []
              0x20   0x22   0x23   0x24
            +------+------+------+------+
Thread 1    |      |  &lt;&gt;  |      |      |
Thread 2    |      |      |      |      |
            +------+------+------+------+
</code></pre>
<p>Right now Thread 1 is accessing <code>0x22</code> via a hazard pointer, so the <code>Protected</code>
list contains the pointer <code>Ox22</code>, annotated with <code>1</code> to indicate Thread 1 is
protecting it. I'm not sure if you would actually keep track of which thread is
protecting a pointer in an actual implementation. I think if another thread
tries to protect an already protected pointer, nothing will happen.</p>
<p>Ok, now, Thread 2 accesses <code>0x22</code> and protects the pointer.</p>
<pre><code>Protected: [1&lt;0x22&gt;, 2&lt;0x22&gt;]
Retired: []
              0x20   0x22   0x23   0x24
            +------+------+------+------+
Thread 1    |      |  &lt;&gt;  |      |      |
Thread 2    |      |  &lt;&gt;  |      |      |
            +------+------+------+------+
</code></pre>
<p>Thread 1 finishes with its access, and retires <code>0x22</code>. Thread 1 is saying, &quot;No
one new will use this pointer, deallocate it when it's safe to do so!&quot; <code>0x22</code> is
added to the <code>Retired</code> list. The <code>Domain</code> can't retire the pointer yet because
Thread 2 is still accessing it.</p>
<pre><code>Protected: [2&lt;0x22&gt;]
Retired: [0x22]
              0x20   0x22   0x23   0x24
            +------+------+------+------+
Thread 1    |      |      |      |      |
Thread 2    |      |  &lt;&gt;  |      |      |
            +------+------+------+------+
</code></pre>
<p>Finally, Thread 2 finishes using the pointer, removing <code>0x22</code> from the
<code>Protected</code> list.</p>
<pre><code>Protected: []
Retired: [0x22]
              0x20   0x22   0x23   0x24
            +------+------+------+------+
Thread 1    |      |      |      |      |
Thread 2    |      |      |      |      |
            +------+------+------+------+
</code></pre>
<p>The <code>Domain</code> sees that <code>0x22</code> is retired and no one is protecting it, so it
deallocates the allocation at <code>0x22</code>. We have reclaimed memory, and <code>0x22</code> will
not leak!</p>
<h2 id="code-changes"><a class="header" href="#code-changes">Code changes</a></h2>
<p>To use the hazard pointers, we're going to need to make a small change in the
vector's structure.</p>
<p>The hardest part was getting started.</p>
<p>Following the documentation on
<a href="https://docs.rs/haphazard/latest/haphazard/struct.Domain.html"><code>Domain</code></a>, I
wrote a bunch of type <code>alias</code>es using the <code>type</code> keyword:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Setting up hazard pointers
// This makes sure they all use the same Domain, guaranteeing the protection is valid.
#[non_exhaustive]
struct Family;
type Domain = haphazard::Domain&lt;Family&gt;;
type HazardPointer&lt;'domain&gt; = haphazard::HazardPointer&lt;'domain, Family&gt;;
type HazAtomicPtr&lt;T&gt; = haphazard::AtomicPtr&lt;T, Family&gt;;
<span class="boring">}</span></code></pre></pre>
<p>We only use <code>Domain</code>s produced from struct <code>Family</code>. This prevents us from
retiring a pointer in the <code>Global</code> domain that is being guarded in a different
domain. The <code>Global</code> domain can't see the other <code>Domain</code>'s protected list, so
might prematurely retire the pointer.</p>
<p>Secondly, all the <code>HazardPointer</code>s and <code>HazAtomicPtr</code>s we construct will be in
same family as our <code>Domain</code>s. This ensures the same protection against
overlapping with the <code>Global</code> domain.</p>
<blockquote>
<p>The difference between <code>HazAtomicPtr</code> which is an an alias for
<code>haphazard::AtomicPtr</code>, and <code>std::sync::atomic::AtomicPtr</code>, is that
<code>HazAtomicPtr</code> uses hazard pointers to guard loads. Additionally, all atomic
operations with <code>HazAtomicPtr</code> have <code>Acquire-Release</code> semantics built in.
Nifty!</p>
</blockquote>
<p>To ensure that we always retire and protect in the same domain, we will also
carry a <code>Domain</code> in the <code>struct</code> itself. Then, it's pretty easy to just always
use <code>&amp;self.domain</code> whenever we need a <code>Domain</code>. All we have to do is add one more
<code>struct</code> field to <code>SecVec</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct SecVec&lt;'a, T: Sized + Copy&gt; {
    buffers: CachePadded&lt;Box&lt;[AtomicPtr&lt;AtomicU64&gt;; 60]&gt;&gt;,
    descriptor: CachePadded&lt;HazAtomicPtr&lt;Descriptor&lt;'a, T&gt;&gt;&gt;,
    domain: Domain, // Hi there :)
    _boo: PhantomData&lt;T&gt;,
}

struct Descriptor&lt;'a, T: Sized&gt; {
    pending: HazAtomicPtr&lt;Option&lt;WriteDescriptor&lt;'a, T&gt;&gt;&gt;,
    size: usize,
}

struct WriteDescriptor&lt;'a, T: Sized&gt; {
    new: u64,
    old: u64,
    location: &amp;'a AtomicU64,
    _boo: PhantomData&lt;T&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>And with that out of the way, we can now plug some leaks!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="fixing-complete_write"><a class="header" href="#fixing-complete_write">Fixing complete_write</a></h1>
<p><code>complete_write</code> was the easiest leak to seal. When we swap out the
<code>WriteDescriptor</code>, we get back the old one. All we have to do is retire it, and
its memory will eventually get reclaimed.</p>
<p>We execute the <code>WriteDescriptor</code> and make a new one (<code>None</code>) like normal:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn complete_write(&amp;self, pending: *mut Option&lt;WriteDescriptor&lt;T&gt;&gt;) {
    // If cas of actual value fails, someone else did the write
    // Result of compare_exchange doesn't matter
    if let Some(writedesc) = unsafe { &amp;*pending } {
        let _ = AtomicU64::compare_exchange(
            writedesc.location,
            writedesc.old,
            writedesc.new,
            Ordering::AcqRel,
            Ordering::Relaxed,
        );

        let new_writedesc = WriteDescriptor::&lt;T&gt;::new_none_as_ptr();

<span class="boring">}</span></code></pre></pre>
<p>Here comes the part where the hazard pointers kick in. We make a hazard pointer
in <code>&amp;self.domain</code>, then load in the <code>Descriptor</code>. Now, the current <code>Descriptor</code>
cannot get reclaimed as long as our hazard pointer is alive. Then we swap in a
new pointer to the <code>None</code> <code>WriteDescriptor</code>.</p>
<p>Here comes the big change, instead of just doing nothing with the pointer that
swapped out, we <code>retire</code> it in <code>&amp;self.domain</code>. According to the documentation
for <code>retire_in</code>, there is a safety contract we need to follow (hence the marking
<code>unsafe fn</code>).</p>
<p>Let's look at that:</p>
<blockquote>
<ol>
<li>The pointed-to object will never again be returned by any
<code>[Haz]AtomicPtr::load</code>.</li>
<li>The pointed-to object has not already been retired.</li>
<li>All calls to load that can have seen the pointed-to object were using
hazard pointers from domain.</li>
</ol>
</blockquote>
<p>Alright, let's make sure we're fulfilling the contract.</p>
<p>Number one, we swapped out the pointer, so all new calls to <code>HazAtomicPtr::load</code>
will use the new pointer. This is <code>Acquire-Release</code> semantics in action under
the hood. Since the <code>swap_ptr</code> uses <code>Release</code>, all <code>HazAtomicPtr::load</code>s (which
use <code>Acquire</code>) will see the new value. Thus, the old value is safe from being
<code>load</code>ed again.</p>
<p>Number two, only one thread can get a pointer as the result of a swap. If I'm
holding a marble in my hand and I give it away, no one else can take that marble
from my hand. The person who took it can do whatever they want with it without
worrying about others interfering. Since we got the pointer as the result of
<code>swap_ptr</code>, no other thread has exclusive access like we do. We took the marble.
Therefore, we know that know other thread has already or might retire the
pointer. They can't access the marble anymore, and if we have the marble, it
means they never had it.</p>
<p>Finally, number 3, all operations (creating hazard pointers, retiring pointers)
happen through <code>&amp;self.domain</code>!</p>
<p>After writing a 1000 word essay, we can confirm that <code>retire_in</code> is safe to
call. This is the argument we'll use for <code>retire</code>ing the results of
<code>compare_exchange</code> in <code>push</code>/<code>pop</code>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>        let mut hp = HazardPointer::new_in_domain(&amp;self.domain);

        let old = unsafe {
            self.descriptor
                .load(&amp;mut hp)
                .expect(&quot;ptr is null&quot;)
                .pending // This is a HazAtomicPtr&lt;WriteDescriptor&gt;
                // # Safety
                // new_writedesc conforms to the requirements of HazAtomicPtr::new()
                // because it comes from Box::into_raw and is a valid WriteDescriptor
                .swap_ptr(new_writedesc)
        };

        // # Safety
        // We are the only thread that will retire this pointer because
        // only one thread can get the result of the swap (this one).
        // Two threads couldn't have performed a swap and both got this pointer.
        unsafe { old.unwrap().retire_in(&amp;self.domain) };

        // hp gets dropped, protection ends
    }
}

<span class="boring">}</span></code></pre></pre>
<p>That's the only change to <code>complete_write</code>. <code>push</code>/<code>pop</code> aren't much worse.</p>
<hr />
<h3 id="complete-source-for-complete_write-not-leaky"><a class="header" href="#complete-source-for-complete_write-not-leaky">Complete source for <code>complete_write</code> (not leaky)</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn complete_write(&amp;self, pending: *mut Option&lt;WriteDescriptor&lt;T&gt;&gt;) {
    // If cas of actual value fails, someone else did the write
    // Result of cmpxchng doesn matter
    if let Some(writedesc) = unsafe { &amp;*pending } {
        let _ = AtomicU64::compare_exchange(
            writedesc.location,
            writedesc.old,
            writedesc.new,
            Ordering::AcqRel,
            Ordering::Relaxed,
        );

        let new_writedesc = WriteDescriptor::&lt;T&gt;::new_none_as_ptr();

        let mut hp = HazardPointer::new_in_domain(&amp;self.domain);

        let old = unsafe {
            self.descriptor
                .load(&amp;mut hp)
                .unwrap()
                .pending
                // # Safety
                // new_writedesc conforms to the requirements of HazAtomicPtr::new()
                // because it comes from Box::into_raw and is a valid WriteDescriptor
                .swap_ptr(new_writedesc)
        };

        // # Safety
        // We are the only thread that will retire this pointer because
        // only one thread can get the result of the swap (this one).
        // Two threads couldn't have performed a swap and both got this pointer.
        unsafe { old.unwrap().retire_in(&amp;self.domain) };
    }
}

<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="fixing-push--pop"><a class="header" href="#fixing-push--pop">Fixing push &amp; pop</a></h1>
<p>I know I said that the changes to <code>push</code> and <code>pop</code> aren't that bad, which is
true. Getting to those changes however, took a while. I'm going to explain what
I did with pseudocode first, and then show the final code.</p>
<p>The first thing I tried was just retiring the old <code>Descriptor</code> after a
successful <code>compare_exchange</code>, however, this didn't reduce the leakage at all
for some reason. I figured it might be because the <code>Descriptor</code> was pointing a
live <code>WriteDescriptor</code>. So then, I also retired the <code>WriteDescriptor</code>. However,
this produced use-after-frees and data races according to <code>Miri</code>, so I knew I
was doing something wrong.</p>
<p>I decided to review the safety contract of <code>retire_in</code> again, and that is when I
found the bug. Retiring the <code>Descriptor</code> is safe for the same reason retiring
the <code>WriteDescriptor</code> after <code>complete_write</code> is. Since the <code>Descriptor</code> is the
result of a swap, we are the only thread who will retire it. The thing is, if we
also retire the <code>WriteDescriptor</code>, a thread who is already accessing the
<code>Descriptor</code> could make a <em>new</em> load to the just retired <code>WriteDescriptor</code>,
violating the safety contract of <code>retire_in</code>, and causing UB.</p>
<h2 id="the-problem-in-picture-form"><a class="header" href="#the-problem-in-picture-form">The problem in picture form</a></h2>
<p>We, Thread 1, have the <code>Descriptor</code> as the result of a successful
<code>compare_exchange</code>. Thread 2 is also reading the <code>Descriptor</code> (<strong>but not the
inner <code>WriteDescriptor</code></strong>)</p>
<pre><code>               Thread 2
               /
Thread 1 (us) /
   |         /
   |        /
   V       v
  Descriptor
     \
      \
       \
        v
        WriteDescriptor
</code></pre>
<p>Because the <code>compare_exchange</code> was successful, we <code>retire</code> the <code>Descriptor</code> and
<code>WriteDescriptor</code>. The <code>Descriptor</code> is protected from reclamation because Thread
2 is reading it, but the <code>WriteDescriptor</code> has no readers so it gets
deallocated.</p>
<pre><code>               Thread 2
               /
Thread 1 (us) /
   |         /
   |        /
   V       v
  Descriptor
     \
   ---+----------------
       \
        v
        WriteDescriptor &lt;Deallocated&gt;
</code></pre>
<p>Now, Thread 2 goes to read the (now reclaimed!!) <code>WriteDescriptor</code> by loading
the pointer contained in the <code>Descriptor</code> (which is still protected, and safe to
access).</p>
<pre><code>               Thread 2
                  |
Thread 1 (us)     |
   |              |
   |              |
   V              |
  Descriptor      |
     \            |
   ---+-----------+----
       \          |
        v         V
        WriteDescriptor &lt;Deallocated&gt;
</code></pre>
<p>And here we have it, Thread 2 accessing deallocated memory!</p>
<h2 id="the-solution"><a class="header" href="#the-solution">The solution</a></h2>
<p>The solution I came up with is to make sure a reference to a <code>WriteDescriptor</code>
never outlives the reference to it's parent <code>Descriptor</code>. Visually this looks
like:</p>
<pre><code>-- Descriptor Reference Start

    -- WriteDescriptor Reference Start


    -- WriteDescriptor Reference End



-- Descriptor Reference End
</code></pre>
<p>This means that when there are no people accessing a <code>Descriptor</code>, there are
also no people accessing the inner <code>WriteDescriptor</code>. Therefore, when a
<code>Descriptor</code> is <code>retired</code>ed, the <code>WriteDescriptor</code> is also safe to <code>retire</code>
because there are no references to it. Since no one can get a new reference to a
<code>retire</code>ed <code>Descriptor</code>, no once can access the inner <code>WriteDescriptor</code>.</p>
<p>Why is this important? Whenever we reclaim a <code>Descriptor</code>, we also reclaim the
inner <code>WriteDescriptor</code>, fixing our leaks without causing any UB.</p>
<p>To implement this custom behavior for <code>Descriptor</code>, we implement the <code>Drop</code>
trait. A type that implements <code>Drop</code> executes some custom behavior when it goes
out of scope and is reclaimed.</p>
<p>The <code>Drop</code> implementation looks like this:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl&lt;T&gt; Drop for Descriptor&lt;'_, T&gt;
{
    fn drop(&amp;mut self) {
        // # Safety
        // The pointer is valid because it's from Box::into_raw
        // We must also ensure ref to wdesc never outlasts ref to desc
        unsafe {
            Box::from_raw(
                self.pending
                    .swap_ptr(ptr::null_mut())
                    .unwrap()
                    .into_inner() // This is a NonNull&lt;T&gt;
                    .as_ptr() // Turn it into a raw pointer
            );
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<p>All we're doing is extracting the pointer to the <code>WriteDescriptor</code> and calling
<code>Box::from_raw</code> on it so that its memory will be reclaimed by <code>Box</code> when it
goes out of scope.</p>
<h2 id="reclaiming-the-descriptors"><a class="header" href="#reclaiming-the-descriptors">Reclaiming the <code>Descriptor</code>s</a></h2>
<p>Its time to finally go over the code changes to <code>push</code>. All accesses to the
<code>Descriptor</code> and <code>WriteDescriptor</code> are guarded with a hazard pointer. The access
returns a reference to the <code>Descriptor</code>/<code>WriteDescriptor</code>, which is valid as
long as the hazard pointer guarding the access is alive. Access to the inner
<code>WriteDescriptor</code> is explicitly scoped within its own block to make clear that
access to the <code>WriteDescriptor</code> cannot outlive the access to the parent
<code>Descriptor</code>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn push(&amp;self, elem: T) {
    let backoff = Backoff::new(); // Backoff causes significant speedup
    loop {
        let mut dhp = HazardPointer::new_in_domain(&amp;self.domain);
        let current_desc = unsafe { self.descriptor.load(&amp;mut dhp) }
            .expect(&quot;invalid ptr for descriptor in push&quot;);

        // Use a block to make explicit that the use of the wdesc does not outlive
        // the use of the desc.
        // This means that when the desc is dropped, there will be no references
        // to the wdesc inside.
        // And we can deallocate the wdesc with `Box::from_raw`
        {
            let mut wdhp = HazardPointer::new_in_domain(&amp;self.domain);
            let pending = unsafe { current_desc.pending.load(&amp;mut wdhp) }
                .expect(&quot;invalid ptr from write-desc in push&quot;);

            self.complete_write(pending as *const _ as *mut _);
            // Hazard pointer is dropped, protection ends
        }
<span class="boring">}</span></code></pre></pre>
<p>This stuff is all the same as before.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>        // If we need more memory, calculate the bucket
        let bucket = (highest_bit(current_desc.size + FIRST_BUCKET_SIZE)
            - highest_bit(FIRST_BUCKET_SIZE)) as usize;
        // Allocate it
        if self.buffers[bucket].load(Ordering::Acquire).is_null() {
            self.allocate_bucket(bucket)
        }

        let last_elem = unsafe { &amp;*self.get(current_desc.size) };

        let next_write_desc = WriteDescriptor::&lt;T&gt;::new_some_as_ptr(
            // TODO: address this in macro
            // # Safety
            // The `transmute_copy` is safe because we have ensured that T is the
            // correct size at compile time
            unsafe { mem::transmute_copy::&lt;T, u64&gt;(&amp;elem) },
            // Load from the AtomicU64, which really contains the bytes for T
            last_elem.load(Ordering::Acquire),
            last_elem,
        );

        let next_desc = Descriptor::&lt;T&gt;::new_as_ptr(next_write_desc,
            current_desc.size + 1);

<span class="boring">}</span></code></pre></pre>
<p>The <code>compare_exchange</code> syntax is slightly different, but it's doing the exact
same thing. We don't have to specify orderings because they're built in by
<code>haphazard</code>. On a successful <code>compare_exchange</code>, we <code>retire</code> the pointer
to the old <code>Descriptor</code>. When it is finally reclaimed, its <code>Drop</code>
implementation will run and its inner <code>WriteDescriptor</code> will also get reclaimed
safely.</p>
<p>If the <code>compare_exchange</code> fails, we deallocate our local <code>Descriptor</code> normally
by calling <code>Box::from_raw</code>. Since the local <code>Descriptor</code> was never shared across
threads, we don't have to worry about synchronizing the deallocation. Then, we
spin using the <code>Backoff</code> and go back to the top of the loop.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>        if let Ok(replaced) = unsafe {
            HazAtomicPtr::compare_exchange_weak_ptr(
                // # Safety
                // Safe because the pointer we swap in points to a valid object that
                // is !null
                &amp;self.descriptor,
                current_desc as *const _ as *mut _,
                next_desc,
            )
        } {
            self.complete_write(next_write_desc);

            // # Safety
            // Since the we only retire when swapping out a pointer, this is the only
            // thread that will retire, since only one thread receives the result of
            // the swap (this one)
            //
            // There will never be another load call to the ptr because all calls will
            // go the new one. Since all uses of the inner wdesc are contained within
            // the lifetime of the reference to the desc, there will also be no new
            // loads on the inner wdesc.
            unsafe {
                replaced.unwrap().retire_in(&amp;self.domain);
            }
            break;
        }

        // Deallocate the write_desc and desc that we failed to swap in
        // # Safety
        // Box the write_desc and desc ptrs were made from Box::into_raw, so it
        // is safe to Box::from_raw
        unsafe {
            // Note: the inner wdesc also get's dropped as part of the desc's drop impl
            Box::from_raw(next_desc);
        }

        backoff.spin();
    }
}

<span class="boring">}</span></code></pre></pre>
<p>The changes for <code>pop</code> are identical. We are so close to being done with code.
Our <code>Descriptor</code>s and <code>WriteDescriptors</code> are eventually reclaimed, which is a
big step forward. The last thing is to deallocate the buckets and the final
<code>Descriptor</code> when the vector itself is dropped.</p>
<hr />
<h3 id="complete-source-for-push-and-pop"><a class="header" href="#complete-source-for-push-and-pop">Complete source for <code>push()</code> and <code>pop()</code></a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn push(&amp;self, elem: T) {
    let backoff = Backoff::new(); // Backoff causes significant speedup
    loop {
        let mut dhp = HazardPointer::new_in_domain(&amp;self.domain);
        let current_desc = unsafe { self.descriptor.load(&amp;mut dhp) }
            .expect(&quot;invalid ptr for descriptor in push&quot;);

        // Use a block to make explicit that the use of the wdesc does not
        // outlive the use of the desc. This means that when the desc is dropped,
        // there will be no references to the wdesc inside.And we can deallocate
        // the wdesc with `Box::from_raw`
        {
            let mut wdhp = HazardPointer::new_in_domain(&amp;self.domain);
            let pending = unsafe { current_desc.pending.load(&amp;mut wdhp) }
                .expect(&quot;invalid ptr from write-desc in push&quot;);

            self.complete_write(pending as *const _ as *mut _);
            // Hazard pointer is dropped, protection ends
        }

        // If we need more memory, calculate the bucket
        let bucket = (highest_bit(current_desc.size + FIRST_BUCKET_SIZE)
            - highest_bit(FIRST_BUCKET_SIZE)) as usize;
        // Allocate it
        if self.buffers[bucket].load(Ordering::Acquire).is_null() {
            self.allocate_bucket(bucket)
        }

        let last_elem = unsafe { &amp;*self.get(current_desc.size) };

        let next_write_desc = WriteDescriptor::&lt;T&gt;::new_some_as_ptr(
            // TODO: address this in macro
            // # Safety
            // The `transmute_copy` is safe because we have ensured that T is
            // the correct size at compile time
            unsafe { mem::transmute_copy::&lt;T, u64&gt;(&amp;elem) },
            // Load from the AtomicU64, which really contains the bytes for T
            last_elem.load(Ordering::Acquire),
            last_elem,
        );

        let next_desc = Descriptor::&lt;T&gt;::new_as_ptr(next_write_desc,
            current_desc.size + 1);

        if let Ok(replaced) = unsafe {
            HazAtomicPtr::compare_exchange_weak_ptr(
                // # Safety
                // Safe because the pointer we swap in points to a valid object that
                // is !null
                &amp;self.descriptor,
                current_desc as *const _ as *mut _,
                next_desc,
            )
        } {
            self.complete_write(next_write_desc);

            // # Safety
            // Since the we only retire when swapping out a pointer, this is the only
            // thread that will retire, since only one thread receives the result of
            // the swap (this one)
            //
            // There will never be another load call to the ptr because all calls will
            // go the new one. Since all uses of the inner wdesc are contained within
            // the lifetime of the reference to the desc, there will also be no new
            // loads on the inner wdesc.
            unsafe {
                replaced.unwrap().retire_in(&amp;self.domain);
            }
            break;
        }

        // Deallocate the write_desc and desc that we failed to swap in
        // # Safety
        // Box the write_desc and desc ptrs were made from Box::into_raw, so it is
        // safe to Box::from_raw
        unsafe {
            // Note: the inner wdesc also get's dropped as part of the desc's drop impl
            Box::from_raw(next_desc);
        }

        backoff.spin();
    }
}

pub fn pop(&amp;self) -&gt; Option&lt;T&gt; {
    let backoff = Backoff::new(); // Backoff causes significant speedup
    loop {
        let mut dhp = HazardPointer::new_in_domain(&amp;self.domain);
        let current_desc = unsafe { self.descriptor.load(&amp;mut dhp) }
            .expect(&quot;invalid ptr for descriptor in pop&quot;);

        // Use a block to make explicit that the use of the wdesc does not
        // outlive the use of the desc. This means that when the desc is
        //  dropped, there will be no references to the wdesc inside.
        // And we can deallocate the wdesc with `Box::from_raw`
        {
            let mut wdhp = HazardPointer::new_in_domain(&amp;self.domain);
            let pending = unsafe { current_desc.pending.load(&amp;mut wdhp) }
                .expect(&quot;invalid ptr for write-descriptor in pop&quot;);

            self.complete_write(pending as *const _ as *mut _);
            // Hazard pointer is dropped, protection ends
        }

        if current_desc.size == 0 {
            return None;
        }

        // TODO: add safety comment
        // Consider if new desc is swapped in, can we read deallocated memory?
        // Do not need to worry about underflow for the sub because we would
        // have already returned
        let elem = unsafe { &amp;*self.get(current_desc.size - 1) }
            .load(Ordering::Acquire);

        let new_pending = WriteDescriptor::&lt;T&gt;::new_none_as_ptr();

        let next_desc = Descriptor::&lt;T&gt;::new_as_ptr(new_pending,
            current_desc.size - 1);

        if let Ok(replaced) = unsafe {
            HazAtomicPtr::compare_exchange_weak_ptr(
                // # Safety
                // Safe because the pointer we swap in points to a valid object that
                // is !null
                &amp;self.descriptor,
                current_desc as *const _ as *mut _,
                next_desc,
            )
        } {
            // # Safety
            // Since the we only retire when swapping out a pointer, this is the only
            // thread that will retire, since only one thread receives the result of
            // the swap (this one)
            //
            // There will never be another load call to the ptr because all calls will
            // go the new one. Since all uses of the inner wdesc are contained within
            // the lifetime of the reference to the desc, there will also be no new
            // loads  on the inner wdesc.
            unsafe {
                replaced.unwrap().retire_in(&amp;self.domain);
            }

            // # Safety
            // TODO: address this in macro
            // This is ok because we ensure T is the correct size at compile time
            // We also know that elem is a valid T because it was transmuted into a
            // usize from a valid T, therefore we are only transmuting it back
            return Some(unsafe { mem::transmute_copy::&lt;u64, T&gt;(&amp;elem) });
        }

        // Deallocate the write_desc and desc that we failed to swap in
        // # Safety
        // Box the write_desc and desc ptrs were made from Box::into_raw, so
        // it is safe to Box::from_raw
        unsafe {
            // Note: the inner wdesc also get's dropped as part of the desc's drop impl
            Box::from_raw(next_desc);
        }

        backoff.spin();
    }
}
<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="dropping-the-vector"><a class="header" href="#dropping-the-vector">Dropping the vector</a></h1>
<p>We approach the end! As its last action, the vector will free the memory
allocated in its buckets and the <code>Descriptor</code> it holds. Once again, we achieve
this by implementing the <code>Drop</code> trait.</p>
<p>Using a bunch of chained function calls on <code>&amp;self.buffers</code>, we can get all of
the buffers that aren't null. Then, we recreate the <code>Layout</code> they hold and
deallocate them.</p>
<p>Dropping the current <code>Descriptor</code> is simple, we just <code>Box::from_raw</code> it!. It's
destructor runs and the inner <code>WriteDescriptor</code> is also deallocated.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl&lt;T&gt; Drop for SecVec&lt;'_, T&gt;
where
    T: Copy,
{
    fn drop(&amp;mut self) {
        // Drop buffers
        let allocator = Global;
        for (bucket, ptr) in self
            .buffers
            .iter()
            .filter(|ptr| !ptr.load(Ordering::Relaxed).is_null())
            .enumerate()
        // Getting all non-null buckets
        {
            let size = FIRST_BUCKET_SIZE * (1 &lt;&lt; bucket);
            let layout = match Layout::array::&lt;AtomicU64&gt;(size) {
                Ok(layout) =&gt; layout,
                Err(_) =&gt; capacity_overflow(),
            };
            unsafe {
                // # Safety
                // We have recreated the exact same layout used to alloc the ptr in
                // `allocate_bucket`. We know the ptr isn't null because of the filter
                allocator.deallocate(
                    NonNull::new(ptr.load(Ordering::Relaxed) as *mut u8).unwrap(),
                    layout,
                )
            };
        }

        // Retiring the current desc and wdesc
        // # Safety
        // Since we have &amp;mut self, we have exclusive access, so we can retire the
        // desc and wdesc ptrs.
        //
        // It is safe to dereference the ptr to the desc because it is valid because
        // it was created with Descriptor::new_as_ptr.
        let desc = self.descriptor.load_ptr();
        unsafe {
            Box::from_raw(desc);
        };
    }
}

<span class="boring">}</span></code></pre></pre>
<p>That's it. All the leaks. All the code I'm going to show you. I hope that was a
satisfying journey from learning about the algorithm to fully implementing it!.
Let's run the tests one more time with <code>Miri :)</code></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="more-tests"><a class="header" href="#more-tests">More tests</a></h1>
<p>Here are the tests. I added a new one up at the top that spawns a bunch of
threads which <code>push</code> and <code>pop</code>. I just want to make sure <code>Miri</code> does not detect
any UB in a complex scenario like that</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod tests {
    use super::*;
    extern crate std;
    use std::sync::atomic::{AtomicIsize, Ordering};
    use std::sync::Arc;
    use std::thread::{self, JoinHandle};
    use std::vec::Vec;

    #[test]
    fn the_big_multithread() {
        static FIVE: isize = 5;
        let data = Arc::new(SecVec::&lt;isize&gt;::new());
        data.reserve(100 * 5);
        let sum = Arc::new(AtomicIsize::new(0));
        #[allow(clippy::needless_collect)]
        let handles = (0..5)
            .map(|_| {
                let data = Arc::clone(&amp;data);
                thread::spawn(move || {
                    for _ in 0..100 {
                        data.push(FIVE);
                    }
                })
            })
            .into_iter()
            .collect::&lt;Vec&lt;JoinHandle&lt;_&gt;&gt;&gt;();
        handles.into_iter().for_each(|h| h.join().unwrap());
        #[allow(clippy::needless_collect)]
        let handles = (0..5)
            .map(|_| {
                let data = Arc::clone(&amp;data);
                let sum = Arc::clone(&amp;sum);
                thread::spawn(move || {
                    for _ in 0..100 {
                        sum.fetch_add(data.pop().unwrap_or(0), Ordering::Relaxed);
                    }
                })
            })
            .into_iter()
            .collect::&lt;Vec&lt;JoinHandle&lt;_&gt;&gt;&gt;();
        handles.into_iter().for_each(|h| h.join().unwrap());
    }

    #[test]
    fn size_starts_at_0() {
        let sv = SecVec::&lt;usize&gt;::new();
        assert_eq!(0, sv.size());
    }

    #[test]
    fn pop_empty_returns_none() {
        let sv = SecVec::&lt;usize&gt;::new();
        assert_eq!(sv.pop(), None);
    }

    #[test]
    fn ten_push_ten_pop() {
        let sv = SecVec::&lt;isize&gt;::new();
        for i in 0..10 {
            sv.push(i);
        }
        for i in (0..10).rev() {
            assert_eq!(sv.pop(), Some(i));
        }
    }

    #[test]
    fn does_not_allocate_buffers_on_new() {
        let sv = SecVec::&lt;isize&gt;::new();
        for buffer in &amp;**sv.buffers {
            assert!(buffer.load(Ordering::Relaxed).is_null())
        }
    }
}

<span class="boring">}</span></code></pre></pre>
<p>And here is the result, shuffled around a little so it all fits:</p>
<pre><code class="language-zsh">~/C/r/unlocked (main) [1] &gt; cargo miri test -- sealed::tests
    Finished test [unoptimized + debuginfo] target(s) in 0.01s
     Running unittests (target/miri/x86_64-apple-darwin/debug/deps/unlocked-666)

running 5 tests
test sealed::tests::does_not_allocate_buffers_on_new ... ok
test sealed::tests::pop_empty_returns_none ... ok
test sealed::tests::size_starts_at_0 ... ok
test sealed::tests::ten_push_ten_pop ... ok
test sealed::tests::the_big_multithread ... ok
    warning: thread support is experimental and incomplete:
        weak memory effects are not emulated.
</code></pre>
<p>Mmm . . . I love those greens! <code>&lt;3</code></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="reflections"><a class="header" href="#reflections">Reflections</a></h1>
<p>Here are some reflections on the process of writing the vector and learning
about concurrent programming.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="potential-optimizations"><a class="header" href="#potential-optimizations">Potential Optimizations</a></h1>
<p>Each time we make a new <code>Descriptor</code> or <code>WriteDescriptor</code>, we allocate it on the
heap. This means we will make many heap allocations for only one <code>Descriptor</code> to
succeed at being <code>compare_exchange</code>'d in. What if we instead made one heap
allocation at the beginning of <code>push</code> and <code>pop</code>, and just overwrote the contents
on every failed iteration of the <code>compare-exchange</code> loop?</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Normal flow
fn push() {
    loop {
        // New allocation every iteration, expensive :(
        &lt;allocate Descriptor&gt; 
        &lt;compare-exchange Descriptor&gt;
        &lt;if compare-exchange failed, reloop&gt;
    }
}

// Efficient flow
fn push() {
    &lt;allocate Descriptor&gt; // One time cost :)
    loop {
        &lt;write to allocation&gt; // Cheap :)
        &lt;compare-exchange Descriptor&gt;
        &lt;if compare-exchange failed, reloop&gt;
    }
}
<span class="boring">}</span></code></pre></pre>
<p>I tried it, and the results range from worse for one microbenchmark to being
somewhat better on other microbenchmarks.</p>
<p>Here's the results of the vector we implemented:</p>
<pre><code>test sealed::bench::pop                ... bench:     169,980 ns/iter (+/- 21,594)
test sealed::bench::push               ... bench:   1,025,550 ns/iter (+/- 43,945)
test sealed::bench::push_and_pop       ... bench:     829,768 ns/iter (+/- 63,895)
test sealed::bench::push_then_pop      ... bench:   1,732,666 ns/iter (+/- 113,670)
</code></pre>
<p>Here's the results for the modified vector:</p>
<pre><code>test sealed::bench::pop                ... bench:     269,311 ns/iter (+/- 11,669)
test sealed::bench::push               ... bench:     962,469 ns/iter (+/- 23,620)
test sealed::bench::push_and_pop       ... bench:     786,135 ns/iter (+/- 32,104)
test sealed::bench::push_then_pop      ... bench:   1,611,816 ns/iter (+/- 68,167)
</code></pre>
<p>As you can see, <code>pop</code> (which is just a bunch of threads <code>pop</code>ing an empty
vector) is worse for the modified vector. At the beginning of <code>pop</code>, we make an
allocation to hold the <code>Descriptor</code>s that we'll try to swap in. However, in this
test, we are always <code>pop</code>ing off an empty vector, so we never even need to write
to the allocation because we just return <code>None</code> when we see the length of the
vector is 0. So, we make an unnecessary allocation when popping off an empty
vector, but save many allocations when there is actual contention.</p>
<p>The other microbenchmarks look better, but the intervals for the modified and
original overlap, so I doubt the change is significant (#AP Stats knowledge).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="unsafe-code"><a class="header" href="#unsafe-code"><code>unsafe</code> code</a></h1>
<p>As I said before, <code>unsafe</code> code isn't inherently bad, it's just code that comes
with a contract. Keeping this in mind helped me get over my initial apprehension
about using <code>unsafe</code> code.</p>
<p>If you write concurrent code, I think <code>unsafe</code> code is inevitable. There's just
too much to do with raw pointers and memory. Additionally, there are many more
contracts the compiler can't enforce in multithreaded scenarios.</p>
<p>Philosophically, concurrent code has to deal with shared mutable state,
otherwise it wouldn't do anything useful. Shared mutable state is inherently
unsafe! That's why <code>Rust</code> only allows one mutable reference (<code>&amp;mut</code>) at a time:
it prevents memory bugs like data races. Thus, there is some danger
intrinsically associated with writing low-level concurrent code.</p>
<blockquote>
<p>&quot;Shared mutable state is, among other things, the root of all evil&quot; - Me, 2022</p>
</blockquote>
<p>Although it seems scary at first, I'm really glad <code>Rust</code> has the concept of
<code>unsafe</code>. Whenever I had any memory bugs, I knew that the root cause must have
been in an <code>unsafe</code> block. Systematically checking over those blocks allowed me
to fix my code quickly.</p>
<p>It's good that we have to make explicit where we are doing potentially unsafe
things. Not just because of debugging, but because it makes us pause and check
everything over one more time. If nothing was <code>unsafe</code>, or everything was
<code>unsafe</code>, reasoning about our code would be much harder in my opinion.</p>
<blockquote>
<p>A note on debugging: <strong>always</strong> read the safety contract and document why what
you're doing is safe! I caught so many bugs just by going over the safety
contract again and realizing I wasn't following it.</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h1 id="atomic-intuition"><a class="header" href="#atomic-intuition">Atomic Intuition</a></h1>
<p>It's pretty safe to say that atomics are confusing. Just the context itself is
confusing: that CPUs and compilers can reorder instructions. I found that as I
developed an intuition for atomics, it became easier to reason about my code and
its correctness.</p>
<p>If you're getting started with concurrent programming, my advice would be to get
a solid grasp on atomics. You don't need to know every detail and all the ins
and outs. When you're writing code and you think &quot;This <code>Acquire</code> load
synchronizes with that <code>Release</code> store&quot;, you gain confidence and it becomes
easier to get going.</p>
<p>The biggest moment for me was when I stopped having to look at the Standard
Library Documentation every time I used an atomic. I had developed an intuitive
sense of the orderings, and I could see why each one was useful in my code. At
first, I thought the orderings seemed a little random. As I started to
use atomics more and more, I saw how the orderings fit in nicely with actual use
cases, from using <code>Acquire</code> to load a bucket to <code>AcqRel</code> in <code>compare_exchange</code>.</p>
<p>Building an intuition for atomics is both satisfying and extremely useful.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="debugging"><a class="header" href="#debugging">Debugging</a></h1>
<p>Here are a couple debugging tricks I stumbled upon out as I wrote the vector.</p>
<h2 id="pointers"><a class="header" href="#pointers">Pointers</a></h2>
<p>One time, I had a problem where something was reading a null pointer. I thought
that after a swap, no thread could read the swapped in value, so I just swapped
in a null pointer. Sadly, I was mistaken. Looking at the error message, which
said <code>pointer 0x0 is invalid to dereference</code>, I got an idea. There were three
places swapping in a null pointer; the first I changed to swap in <code>0x1</code>, the
second <code>0x2</code>, and the third <code>0x3</code>.</p>
<p>After running the program through <code>Miri</code>, I got the error message
<code>pointer 0x2 is invalid to dereference</code>, and I knew where the bug was
originating from.</p>
<h2 id="unwrap-vs-expect"><a class="header" href="#unwrap-vs-expect"><code>unwrap</code> vs. <code>expect</code></a></h2>
<p>Whenever you <code>unwrap</code> an <code>Option</code> or <code>Result</code> that is <code>None</code> or <code>Err</code>, Rust will
print out a little diagnostic saying where the <code>panic!</code> happened. I found it
helpful to use <code>expect</code> instead of <code>unwrap</code> because of the ability to provide
some extra context.</p>
<p>For example, there is a method in the <code>haphazard</code> crate called <code>AtomicPtr::load</code>
which returns an <code>Option&lt;&amp;T&gt;</code>. It only returns a <code>None</code> value if the underlying
<code>AtomicPtr</code> contains a null pointer. Instead of <code>unwrap</code>ing the return value of
<code>load</code>, I called <code>expect(&quot;read null pointer&quot;)</code>. When I inevitably messed up and
<code>unwrap</code>ed a <code>None</code>, I new there was a null pointer floating around because of
the error message.</p>
<blockquote>
<p>Although these tricks seem small, they actually saved me a lot of time.</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h1 id="acknowledgements"><a class="header" href="#acknowledgements">Acknowledgements</a></h1>
<p>Thank you to my advisor and my friends for your feedback and support.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="helpful-resources"><a class="header" href="#helpful-resources">Helpful Resources</a></h1>
<ul>
<li><a href="https://doc.rust-lang.org/stable/std/">Rust Standard Library Documentation</a></li>
<li><a href="https://www.youtube.com/c/JonGjengset">Jon Gjenset's Youtube Channel</a></li>
<li><a href="https://doc.rust-lang.org/stable/book/">The Book</a></li>
<li><a href="https://doc.rust-lang.org/stable/reference/">The Rust Reference</a></li>
<li><a href="https://doc.rust-lang.org/nightly/nomicon/intro.html">The Rustonomicon</a></li>
<li><a href="https://preshing.com/">Preshing's Blog</a> (especially his content on atomics
and lock-free programming!)</li>
<li><a href="https://rust-unofficial.github.io/too-many-lists/">Learn Rust With Entirely Too Many Linked Lists</a></li>
</ul>
<blockquote>
<p>Reading source code is a great way to learn!</p>
</blockquote>
<ul>
<li><a href="https://docs.rs/crossbeam-queue/latest/crossbeam_queue/"><code>crossbeam_queue</code></a></li>
<li><a href="https://docs.rs/crossbeam-utils/latest/crossbeam_utils/"><code>crossbeam_utils</code></a></li>
<li><a href="https://docs.rs/atomic/latest/atomic"><code>atomic</code></a></li>
<li><a href="https://docs.rs/haphazard/latest/haphazard"><code>haphazard</code></a></li>
<li><a href="https://doc.rust-lang.org/stable/src/alloc/vec/mod.rs.html#400-403"><code>std::vec::Vec</code></a>
(also check out
<a href="https://doc.rust-lang.org/stable/src/alloc/raw_vec.rs.html"><code>RawVec</code></a>)</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script>
            const wsProtocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsAddress = wsProtocol + "//" + location.host + "/" + "__livereload";
            const socket = new WebSocket(wsAddress);
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </body>
</html>
